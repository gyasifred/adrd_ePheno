#!/usr/bin/env Rscript
# ==============================================================================
# ADRD ePhenotyping Pipeline - AIM 2: Feature Analysis & Explainability
# ==============================================================================
# Version: 2.0
# Author: Gyasi, Frederick
# Evaluation Using Jihad Obeid's Pre-Trained Models
#
# üéØ KEY: Uses predictions from Jihad's models (generated by 03_evaluate_models.R)
# üéØ Loads Jihad's trained model for LIME and behavioral testing
#
# Purpose: Identify cohort-specific features and model sensitivity
#
# Aim 2 Objectives:
# 1. Corpus Analysis - Identify overrepresented terms using œá¬≤ testing
# 2. TF-IDF Analysis - Find discriminative features
# 3. LIME Explainability - Understand individual predictions (NEW in v2.0)
# 4. Behavioral Testing - Term removal sensitivity analysis (NEW in v2.0)
# 5. Feature Importance Visualization
#
# Methodology:
# - œá¬≤-squared testing for term significance
# - Term frequency-inverse document frequency (TF-IDF)
# - Local Interpretable Model-agnostic Explanations (LIME)
# - Behavioral testing with discriminative term removal
#
# Inputs:  data/train_set.rds, data/test_set.rds,
#          models/*, results/predictions_df.csv
# Outputs: results/aim2/*, figures/aim2/*, behavioral_testing_template.R
# ==============================================================================

# Define operators FIRST
`%+%` <- function(a, b) paste0(a, b)

# Load Libraries ==============================================================
cat(strrep("=", 80) %+% "\n")
cat("ADRD ePhenotyping - AIM 2: Feature Analysis & Explainability\n")
cat(strrep("=", 80) %+% "\n\n")

cat("Loading required libraries...\n")
suppressPackageStartupMessages({
  library(tidyverse)      # Data manipulation
  library(quanteda)       # Text analysis
  library(quanteda.textstats)  # Text statistics
  library(quanteda.textplots)  # Text plots
  library(ggplot2)        # Visualization
  library(gridExtra)      # Multiple plots
  library(scales)         # Plot formatting
  library(writexl)        # Excel export
  library(wordcloud)      # Word clouds
  library(RColorBrewer)   # Color palettes
  library(ggrepel)        # Better plot labels
  library(keras)          # For loading trained model
  library(reticulate)     # Python interface
})

options(dplyr.summarise.inform = FALSE)
quanteda_options(threads = 4)  # Parallel processing

# Configuration ===============================================================
cat("\nConfiguration:\n")
cat(strrep("-", 80) %+% "\n")

# Paths
DATA_DIR <- "data"
MODEL_DIR <- "models"
RESULTS_DIR <- "results"
FIGURES_DIR <- "figures"

# Create subdirectories for Aim 2 results
AIM2_RESULTS_DIR <- file.path(RESULTS_DIR, "aim2")
AIM2_FIGURES_DIR <- file.path(FIGURES_DIR, "aim2")
dir.create(AIM2_RESULTS_DIR, showWarnings = FALSE, recursive = TRUE)
dir.create(AIM2_FIGURES_DIR, showWarnings = FALSE, recursive = TRUE)

# Analysis parameters
TOP_N_FEATURES <- 100        # Top N features to report
MIN_TERM_FREQ <- 10          # Minimum term frequency for analysis
CHI_SQUARE_ALPHA <- 0.05     # Significance level for œá¬≤ test
FDR_METHOD <- "BH"           # False discovery rate method (Benjamini-Hochberg)

cat("  Top N features:", TOP_N_FEATURES, "\n")
cat("  Min term frequency:", MIN_TERM_FREQ, "\n")
cat("  Chi-square alpha:", CHI_SQUARE_ALPHA, "\n")
cat("  FDR correction:", FDR_METHOD, "\n\n")

# Load Data ===================================================================
cat(strrep("=", 80) %+% "\n")
cat("Loading Data\n")
cat(strrep("=", 80) %+% "\n\n")

# Load train and test sets
train_file <- file.path(DATA_DIR, "train_set.rds")
test_file <- file.path(DATA_DIR, "test_set.rds")

if (!file.exists(test_file)) {
  stop("Data files not found! Run 01_prepare_data.R first.")
}

# NOTE: train_set is minimal reference only (10 samples)
# test_set contains FULL DATASET (all patients)
# We use ONLY test_set to avoid duplicates
test_set <- readRDS(test_file)

cat("Test set (FULL DATASET):", nrow(test_set), "samples\n")
cat("Note: Using test set only (contains all data)\n")

# Use test set as full corpus (no train/test split for evaluation)
full_corpus <- test_set %>% mutate(partition = "test")

cat("Total corpus:", nrow(full_corpus), "documents\n\n")

# Display class distribution
cat("Class distribution:\n")
print(table(full_corpus$label))
cat("\n")

# Load predictions (for LIME analysis)
pred_file <- file.path(RESULTS_DIR, "predictions_df.csv")
if (file.exists(pred_file)) {
  predictions <- read_csv(pred_file, show_col_types = FALSE)
  cat("Predictions loaded:", nrow(predictions), "samples\n\n")
} else {
  cat("WARNING: predictions_df.csv not found. LIME analysis will be skipped.\n\n")
  predictions <- NULL
}

# ==============================================================================
# PART 1: CORPUS ANALYSIS
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("PART 1: Corpus Analysis\n")
cat(strrep("=", 80) %+% "\n\n")

# Create corpus object
cat("Creating quanteda corpus...\n")
adrd_corpus <- corpus(full_corpus, text_field = "txt", docid_field = "DE_ID")

# Add document variables
docvars(adrd_corpus, "label") <- full_corpus$label
docvars(adrd_corpus, "label_str") <- ifelse(full_corpus$label == 1, "ADRD", "CTRL")
docvars(adrd_corpus, "partition") <- full_corpus$partition

cat("  Documents:", ndoc(adrd_corpus), "\n")
cat("  ADRD:", sum(docvars(adrd_corpus, "label") == 1), "\n")
cat("  CTRL:", sum(docvars(adrd_corpus, "label") == 0), "\n\n")

# Tokenization
cat("Tokenizing corpus...\n")
adrd_tokens <- tokens(
  adrd_corpus,
  what = "word",
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_numbers = FALSE,  # Keep numbers (might be clinically relevant)
  remove_url = TRUE,
  remove_separators = TRUE,
  split_hyphens = FALSE
)

# Remove stopwords and masked tokens ONLY
cat("Removing stopwords and masked tokens...\n")
adrd_tokens <- tokens_remove(adrd_tokens, pattern = stopwords("en"))

# Remove ONLY masked tokens from de-identification (tokens with underscores)
# These are artifacts from data preprocessing/masking: _decnum_, _time_, _date_, etc.
masked_tokens <- c(
  "_decnum_", "_time_", "_date_", "_phonenum_", "_ssn_", "_mrn_",
  "_num_", "_id_", "_email_", "_url_", "_name_", "_address_",
  "_age_", "_dob_", "_zip_", "_fax_", "_hipaa_", "_lgnum_"
)

cat("  Removing", length(masked_tokens), "masked tokens (de-identification artifacts)\n")
adrd_tokens <- tokens_remove(adrd_tokens, pattern = masked_tokens, valuetype = "fixed")

# Define function to filter non-significant terms for visualization/interpretation
# These terms are kept in the DFM for analysis but filtered for human review
filter_nonsignificant_terms <- function(term_data, term_col = "feature") {
  #' Filter out non-clinically-meaningful terms for visualization
  #'
  #' Removes:
  #' - Single characters (s, o, x, etc.)
  #' - Pure numbers (1, 2, 3, etc.)
  #' - Remaining masked tokens (any token with underscores)
  #' - Very short non-word tokens (mg, ml kept as medically relevant)
  #'
  #' @param term_data Data frame with terms
  #' @param term_col Name of column containing terms
  #' @return Filtered data frame

  term_data %>%
    filter(
      # Remove single characters
      nchar(.data[[term_col]]) > 1,
      # Remove pure numbers
      !grepl("^[0-9]+$", .data[[term_col]]),
      # Remove remaining masked tokens (anything with underscores)
      !grepl("_", .data[[term_col]]),
      # Keep only terms that are at least 2 chars OR are medically relevant abbreviations
      nchar(.data[[term_col]]) >= 2
    )
}

# Create Document-Feature Matrix
cat("Creating document-feature matrix...\n")
adrd_dfm <- dfm(adrd_tokens)

cat("  Features (unique terms):", nfeat(adrd_dfm), "\n")
cat("  Documents:", ndoc(adrd_dfm), "\n\n")

# Trim rare features
cat("Trimming rare features (min frequency = ", MIN_TERM_FREQ, ")...\n", sep = "")
adrd_dfm_trimmed <- dfm_trim(adrd_dfm, min_termfreq = MIN_TERM_FREQ)

cat("  Features after trimming:", nfeat(adrd_dfm_trimmed), "\n\n")

# ==============================================================================
# PART 2: WORD FREQUENCY ANALYSIS
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("PART 2: Word Frequency Analysis\n")
cat(strrep("=", 80) %+% "\n\n")

# Overall frequency
cat("Calculating overall term frequencies...\n")
term_freq_all <- textstat_frequency(adrd_dfm_trimmed)

# Filter for display (keep raw data for analysis)
term_freq_all_clean <- filter_nonsignificant_terms(term_freq_all, "feature")

cat("  Top 20 most frequent clinically relevant terms:\n")
print(head(term_freq_all_clean, 20))
cat("\n")

# Frequency by class
cat("Calculating term frequencies by class (ADRD vs CTRL)...\n")
adrd_dfm_grouped <- dfm_group(adrd_dfm_trimmed, groups = label_str)

term_freq_by_class <- textstat_frequency(adrd_dfm_grouped,
                                         groups = label_str)

# Filter for display
term_freq_by_class_clean <- filter_nonsignificant_terms(term_freq_by_class, "feature")

cat("  Top 10 clinically relevant terms in ADRD notes:\n")
print(head(term_freq_by_class_clean %>% filter(group == "ADRD"), 10))
cat("\n")

cat("  Top 10 clinically relevant terms in CTRL notes:\n")
print(head(term_freq_by_class_clean %>% filter(group == "CTRL"), 10))
cat("\n")

# Save frequency tables
write_csv(term_freq_all,
          file.path(AIM2_RESULTS_DIR, "term_frequencies_overall.csv"))
write_csv(term_freq_by_class,
          file.path(AIM2_RESULTS_DIR, "term_frequencies_by_class.csv"))
cat("Frequency tables saved\n\n")

# ==============================================================================
# PART 3: CHI-SQUARED TEST FOR DISCRIMINATIVE TERMS
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("PART 3: Chi-Squared Test for Discriminative Terms\n")
cat(strrep("=", 80) %+% "\n\n")

cat("Performing chi-squared test...\n")

# Calculate chi-squared statistics
chi2_results <- textstat_keyness(adrd_dfm_grouped,
                                  target = "ADRD",
                                  measure = "chi2")

# Sort by chi-squared value
chi2_results <- chi2_results %>%
  arrange(desc(chi2)) %>%
  mutate(
    # Calculate p-value from chi-squared (df=1 for 2x2 table)
    p_value = pchisq(chi2, df = 1, lower.tail = FALSE),
    # Apply FDR correction
    p_adjusted = p.adjust(p_value, method = FDR_METHOD),
    # Determine significance
    significant = p_adjusted < CHI_SQUARE_ALPHA
  )

cat("  Total features tested:", nrow(chi2_results), "\n")
cat("  Significant features (FDR < ", CHI_SQUARE_ALPHA, "): ",
    sum(chi2_results$significant, na.rm = TRUE), "\n\n", sep = "")

# Extract top discriminative terms
top_adrd_terms <- chi2_results %>%
  filter(chi2 > 0, significant) %>%  # Positive chi2 = overrepresented in ADRD
  arrange(desc(chi2)) %>%
  head(TOP_N_FEATURES)

top_ctrl_terms <- chi2_results %>%
  filter(chi2 < 0, significant) %>%  # Negative chi2 = overrepresented in CTRL
  arrange(chi2) %>%
  head(TOP_N_FEATURES)

# Filter for display (but keep unfiltered for saving to files)
top_adrd_terms_clean <- filter_nonsignificant_terms(top_adrd_terms, "feature")
top_ctrl_terms_clean <- filter_nonsignificant_terms(top_ctrl_terms, "feature")

cat("Top 20 clinically relevant terms overrepresented in ADRD:\n")
print(head(top_adrd_terms_clean, 20))
cat("\n")

cat("Top 20 clinically relevant terms overrepresented in CTRL:\n")
print(head(top_ctrl_terms_clean, 20))
cat("\n")

# Save chi-squared results
write_csv(chi2_results,
          file.path(AIM2_RESULTS_DIR, "chi_squared_results.csv"))
write_xlsx(list(
  All_Results = chi2_results,
  Top_ADRD = top_adrd_terms,
  Top_CTRL = top_ctrl_terms
), file.path(AIM2_RESULTS_DIR, "discriminative_terms.xlsx"))
cat("Chi-squared results saved\n\n")

# ==============================================================================
# PART 1B: DEMOGRAPHIC-STRATIFIED CHI-SQUARED ANALYSIS
# ==============================================================================
# PURPOSE: Identify if discriminative terms differ by demographic subgroups

cat(strrep("=", 80) %+% "\n")
cat("PART 1B: Demographic-Stratified Chi-Squared Analysis\n")
cat(strrep("=", 80) %+% "\n\n")

cat("Investigating if discriminative features differ by demographics...\n\n")

# Check for demographic variables in full_corpus
demo_vars_available <- c()
for (demo in c("GENDER", "RACE", "HISPANIC")) {
  if (demo %in% names(full_corpus)) {
    demo_vars_available <- c(demo_vars_available, demo)
    cat("  Found demographic variable:", demo, "\n")
  }
}

if (length(demo_vars_available) == 0) {
  cat("\n‚ö†Ô∏è  No demographic variables found in corpus.\n")
  cat("   Demographic feature analysis will be skipped.\n\n")
} else {
  cat("\nDemographic variables available:", paste(demo_vars_available, collapse = ", "), "\n\n")

  # Storage for demographic-stratified results
  demo_chi2_results <- list()

  # Analyze for each demographic variable
  for (demo_var in demo_vars_available) {

    cat(strrep("-", 80) %+% "\n")
    cat("Analyzing:", demo_var, "\n")
    cat(strrep("-", 80) %+% "\n\n")

    # Get unique demographic values (exclude NA, empty, UNKNOWN)
    demo_values <- full_corpus %>%
      filter(!is.na(.data[[demo_var]]),
             .data[[demo_var]] != "",
             .data[[demo_var]] != "UNKNOWN") %>%
      pull(.data[[demo_var]]) %>%
      unique()

    # Normalize gender values if needed
    if (demo_var == "GENDER") {
      full_corpus <- full_corpus %>%
        mutate(GENDER = case_when(
          toupper(GENDER) %in% c("FEMALE", "F") ~ "Female",
          toupper(GENDER) %in% c("MALE", "M") ~ "Male",
          TRUE ~ GENDER
        ))
      demo_values <- c("Female", "Male")
    }

    cat("Subgroups:", paste(demo_values, collapse = ", "), "\n\n")

    # For each demographic subgroup, calculate chi-squared terms
    demo_var_results <- list()

    for (demo_val in demo_values) {

      # Filter corpus to this demographic subgroup
      subgroup_corpus <- full_corpus %>%
        filter(.data[[demo_var]] == demo_val)

      # Check minimum sample sizes
      n_adrd <- sum(subgroup_corpus$label == 1, na.rm = TRUE)
      n_ctrl <- sum(subgroup_corpus$label == 0, na.rm = TRUE)

      if (n_adrd < 20 || n_ctrl < 20) {
        cat("  Skipping", demo_val, "(insufficient samples: ADRD=", n_adrd, ", CTRL=", n_ctrl, ")\n")
        next
      }

      cat("  Analyzing", demo_val, "(N =", nrow(subgroup_corpus),
          ": ADRD=", n_adrd, ", CTRL=", n_ctrl, ")\n")

      # Create corpus for this subgroup
      sub_corpus <- corpus(subgroup_corpus, text_field = "txt", docid_field = "DE_ID")
      docvars(sub_corpus, "label_str") <- ifelse(subgroup_corpus$label == 1, "ADRD", "CTRL")

      # Tokenize and create DFM
      sub_tokens <- tokens(sub_corpus,
                           remove_punct = TRUE,
                           remove_symbols = TRUE,
                           remove_numbers = TRUE) %>%
        tokens_tolower() %>%
        tokens_remove(pattern = stopwords("en")) %>%
        tokens_remove(pattern = masked_tokens, valuetype = "fixed")

      sub_dfm <- dfm(sub_tokens) %>%
        dfm_trim(min_termfreq = 5, min_docfreq = 3)

      # Group by label
      sub_dfm_grouped <- dfm_group(sub_dfm, groups = label_str)

      # Calculate chi-squared
      tryCatch({
        chi2_sub <- textstat_keyness(sub_dfm_grouped,
                                     target = "ADRD",
                                     measure = "chi2")

        # Get top 20 terms
        top_terms <- chi2_sub %>%
          arrange(desc(chi2)) %>%
          head(20) %>%
          mutate(
            demographic = demo_var,
            subgroup = demo_val,
            p_value = pchisq(chi2, df = 1, lower.tail = FALSE)
          )

        demo_var_results[[demo_val]] <- top_terms

        cat("    Top 5 discriminative terms:",
            paste(head(top_terms$feature, 5), collapse = ", "), "\n")

      }, error = function(e) {
        cat("    Error in chi-squared calculation:", e$message, "\n")
      })
    }

    # Store results for this demographic variable
    if (length(demo_var_results) > 0) {
      demo_chi2_results[[demo_var]] <- demo_var_results

      # Compare top terms across subgroups
      if (length(demo_var_results) >= 2) {
        cat("\n  Comparing discriminative terms across", demo_var, "subgroups:\n")

        # Get top 10 terms for each subgroup
        all_top_terms <- lapply(names(demo_var_results), function(sg) {
          demo_var_results[[sg]] %>%
            head(10) %>%
            pull(feature)
        })
        names(all_top_terms) <- names(demo_var_results)

        # Calculate overlap
        if (length(all_top_terms) == 2) {
          overlap <- intersect(all_top_terms[[1]], all_top_terms[[2]])
          cat("    Common terms (top 10):", length(overlap), "/", 10, "\n")
          if (length(overlap) > 0) {
            cat("      ", paste(overlap, collapse = ", "), "\n")
          }

          # Unique to each group
          unique_1 <- setdiff(all_top_terms[[1]], all_top_terms[[2]])
          unique_2 <- setdiff(all_top_terms[[2]], all_top_terms[[1]])

          if (length(unique_1) > 0) {
            cat("    Unique to", names(all_top_terms)[1], ":",
                paste(unique_1, collapse = ", "), "\n")
          }
          if (length(unique_2) > 0) {
            cat("    Unique to", names(all_top_terms)[2], ":",
                paste(unique_2, collapse = ", "), "\n")
          }

          # Interpretation
          overlap_pct <- length(overlap) / 10 * 100
          if (overlap_pct < 50) {
            cat("\n    ‚ö†Ô∏è  FINDING: Low term overlap (", sprintf("%.0f%%", overlap_pct),
                ") suggests different linguistic patterns by ", demo_var, "\n", sep = "")
          } else {
            cat("\n    ‚úì Good term overlap (", sprintf("%.0f%%", overlap_pct),
                ") - consistent patterns across ", demo_var, "\n", sep = "")
          }
        }
      }
    }
    cat("\n")
  }

  # Save demographic-stratified chi-squared results
  if (length(demo_chi2_results) > 0) {
    saveRDS(demo_chi2_results,
            file.path(AIM2_RESULTS_DIR, "demographic_chi2_stratified.rds"))

    # Create comparison table
    comparison_df <- bind_rows(lapply(names(demo_chi2_results), function(demo) {
      bind_rows(lapply(names(demo_chi2_results[[demo]]), function(sg) {
        demo_chi2_results[[demo]][[sg]] %>%
          head(20) %>%
          select(feature, chi2, p_value) %>%
          mutate(demographic = demo, subgroup = sg)
      }))
    }))

    write_csv(comparison_df,
              file.path(AIM2_RESULTS_DIR, "demographic_chi2_comparison.csv"))

    cat("Demographic-stratified chi-squared results saved\n\n")
  }
}

# ==============================================================================
# PART 4: TF-IDF ANALYSIS
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("PART 4: TF-IDF Analysis\n")
cat(strrep("=", 80) %+% "\n\n")

cat("Calculating TF-IDF weights...\n")

# Calculate TF-IDF
adrd_tfidf <- dfm_tfidf(adrd_dfm_grouped)

# Extract top TF-IDF terms for each class
top_tfidf_adrd <- topfeatures(adrd_tfidf[docid(adrd_tfidf) == "ADRD", ],
                               n = TOP_N_FEATURES)
top_tfidf_ctrl <- topfeatures(adrd_tfidf[docid(adrd_tfidf) == "CTRL", ],
                               n = TOP_N_FEATURES)

# Filter for display - convert to data frame, filter, then back to named vector
top_tfidf_adrd_df <- data.frame(feature = names(top_tfidf_adrd),
                                  tfidf = as.numeric(top_tfidf_adrd),
                                  stringsAsFactors = FALSE)
top_tfidf_adrd_clean_df <- filter_nonsignificant_terms(top_tfidf_adrd_df, "feature")
top_tfidf_adrd_clean <- setNames(top_tfidf_adrd_clean_df$tfidf,
                                   top_tfidf_adrd_clean_df$feature)

top_tfidf_ctrl_df <- data.frame(feature = names(top_tfidf_ctrl),
                                  tfidf = as.numeric(top_tfidf_ctrl),
                                  stringsAsFactors = FALSE)
top_tfidf_ctrl_clean_df <- filter_nonsignificant_terms(top_tfidf_ctrl_df, "feature")
top_tfidf_ctrl_clean <- setNames(top_tfidf_ctrl_clean_df$tfidf,
                                   top_tfidf_ctrl_clean_df$feature)

cat("  Top 20 clinically relevant TF-IDF terms for ADRD:\n")
print(head(top_tfidf_adrd_clean, 20))
cat("\n")

cat("  Top 20 clinically relevant TF-IDF terms for CTRL:\n")
print(head(top_tfidf_ctrl_clean, 20))
cat("\n")

# Save TF-IDF results
tfidf_results <- data.frame(
  ADRD_term = names(top_tfidf_adrd),
  ADRD_tfidf = as.numeric(top_tfidf_adrd),
  CTRL_term = names(top_tfidf_ctrl),
  CTRL_tfidf = as.numeric(top_tfidf_ctrl)
)

write_csv(tfidf_results,
          file.path(AIM2_RESULTS_DIR, "tfidf_top_terms.csv"))
cat("TF-IDF results saved\n\n")

# ==============================================================================
# PART 4B: DEMOGRAPHIC-STRATIFIED TF-IDF ANALYSIS
# ==============================================================================
# PURPOSE: Compare TF-IDF patterns across demographic subgroups to identify
#          which clinical phrases drive performance differences
# METHOD:  Calculate TF-IDF for correctly vs incorrectly classified patients
#          within each demographic group, then compare "keyness" terms
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("PART 4B: Demographic-Stratified TF-IDF Analysis\n")
cat(strrep("=", 80) %+% "\n\n")

cat("Analyzing TF-IDF patterns across demographic subgroups...\n\n")

# TF-IDF EXPLANATION (for Methods section):
# - Term Frequency (TF): How often a term appears in a document/subgroup
# - Inverse Document Frequency (IDF): How unique/rare a term is across corpus
# - TF-IDF = TF √ó IDF (high score = important AND distinctive)
# - Used to identify discriminative clinical phrases by demographic subgroup
# - High TF-IDF = term appears frequently in one subgroup but rarely in others

# Check if we have predictions and demographic variables
if (is.null(predictions)) {
  cat("‚ö†Ô∏è  Predictions not available. Skipping demographic TF-IDF analysis.\n\n")
} else {

  # Merge predictions with full corpus data
  full_corpus_with_preds <- full_corpus %>%
    left_join(predictions %>% select(DE_ID, Predicted_Class, Predicted_Probability, Correct),
              by = "DE_ID")

  # Check for demographic variables
  demo_vars_tfidf <- c()
  for (demo in c("GENDER", "RACE", "HISPANIC")) {
    if (demo %in% names(full_corpus_with_preds)) {
      demo_vars_tfidf <- c(demo_vars_tfidf, demo)
      cat("  Found demographic variable:", demo, "\n")
    }
  }

  if (length(demo_vars_tfidf) == 0) {
    cat("\n‚ö†Ô∏è  No demographic variables found.\n")
    cat("   Demographic TF-IDF analysis will be skipped.\n\n")
  } else {
    cat("\nDemographic variables available:", paste(demo_vars_tfidf, collapse = ", "), "\n\n")

    # Storage for demographic-stratified TF-IDF results
    demo_tfidf_results <- list()
    demo_tfidf_comparison <- list()

    # Analyze for each demographic variable
    for (demo_var in demo_vars_tfidf) {

      cat(strrep("-", 80) %+% "\n")
      cat("Analyzing TF-IDF for:", demo_var, "\n")
      cat(strrep("-", 80) %+% "\n\n")

      # Normalize demographic values
      if (demo_var == "GENDER") {
        full_corpus_with_preds <- full_corpus_with_preds %>%
          mutate(GENDER = case_when(
            toupper(GENDER) %in% c("FEMALE", "F") ~ "Female",
            toupper(GENDER) %in% c("MALE", "M") ~ "Male",
            TRUE ~ GENDER
          ))
      }

      # Get unique demographic values (exclude NA, empty, UNKNOWN)
      demo_values <- full_corpus_with_preds %>%
        filter(!is.na(.data[[demo_var]]),
               .data[[demo_var]] != "",
               .data[[demo_var]] != "UNKNOWN") %>%
        pull(.data[[demo_var]]) %>%
        unique()

      cat("Subgroups:", paste(demo_values, collapse = ", "), "\n\n")

      # For each demographic subgroup, calculate TF-IDF for correct vs incorrect
      demo_var_tfidf <- list()

      for (demo_val in demo_values) {

        # Filter to this demographic subgroup
        subgroup_data <- full_corpus_with_preds %>%
          filter(.data[[demo_var]] == demo_val,
                 partition == "test")  # Only test set has predictions

        # Use existing classification correctness indicator from predictions
        subgroup_data <- subgroup_data %>%
          mutate(correct = Correct)

        # Check minimum sample sizes
        n_correct <- sum(subgroup_data$correct, na.rm = TRUE)
        n_incorrect <- sum(!subgroup_data$correct, na.rm = TRUE)

        if (n_correct < 20 || n_incorrect < 20) {
          cat("  Skipping", demo_val,
              "(insufficient samples: Correct=", n_correct,
              ", Incorrect=", n_incorrect, ")\n")
          next
        }

        cat("  Analyzing", demo_val,
            "(N =", nrow(subgroup_data),
            ": Correct=", n_correct,
            ", Incorrect=", n_incorrect, ")\n")

        # Create corpus for this subgroup
        sub_corpus <- corpus(subgroup_data,
                            text_field = "txt",
                            docid_field = "DE_ID")
        docvars(sub_corpus, "correct_str") <- ifelse(subgroup_data$correct,
                                                     "Correct",
                                                     "Incorrect")

        # Tokenize and create DFM
        sub_tokens <- tokens(sub_corpus,
                            remove_punct = TRUE,
                            remove_symbols = TRUE,
                            remove_numbers = TRUE) %>%
          tokens_tolower() %>%
          tokens_remove(pattern = stopwords("en")) %>%
          tokens_remove(pattern = masked_tokens, valuetype = "fixed")

        sub_dfm <- dfm(sub_tokens) %>%
          dfm_trim(min_termfreq = 5, min_docfreq = 3)

        # Group by correctness
        sub_dfm_grouped <- dfm_group(sub_dfm, groups = correct_str)

        # Calculate TF-IDF
        sub_tfidf <- dfm_tfidf(sub_dfm_grouped)

        # Extract top TF-IDF terms
        tryCatch({
          if ("Correct" %in% docid(sub_tfidf)) {
            top_correct <- topfeatures(sub_tfidf[docid(sub_tfidf) == "Correct", ],
                                      n = 50)
          } else {
            top_correct <- numeric(0)
          }

          if ("Incorrect" %in% docid(sub_tfidf)) {
            top_incorrect <- topfeatures(sub_tfidf[docid(sub_tfidf) == "Incorrect", ],
                                        n = 50)
          } else {
            top_incorrect <- numeric(0)
          }

          # Store results
          demo_var_tfidf[[demo_val]] <- list(
            correct = top_correct,
            incorrect = top_incorrect,
            n_correct = n_correct,
            n_incorrect = n_incorrect
          )

          cat("    Top 10 TF-IDF terms for Correct classifications:\n")
          if (length(top_correct) > 0) {
            print(head(top_correct, 10))
          } else {
            cat("      (none)\n")
          }
          cat("\n")

          cat("    Top 10 TF-IDF terms for Incorrect classifications:\n")
          if (length(top_incorrect) > 0) {
            print(head(top_incorrect, 10))
          } else {
            cat("      (none)\n")
          }
          cat("\n\n")

        }, error = function(e) {
          cat("    Error calculating TF-IDF:", e$message, "\n\n")
        })
      }

      # Store results for this demographic variable
      demo_tfidf_results[[demo_var]] <- demo_var_tfidf

      # Create comparison table for this demographic variable
      comparison_rows <- list()

      for (demo_val in names(demo_var_tfidf)) {
        result <- demo_var_tfidf[[demo_val]]

        # Get top 20 terms for each
        n_terms <- min(20, length(result$correct), length(result$incorrect))

        if (n_terms > 0) {
          comparison_rows[[demo_val]] <- data.frame(
            demographic = demo_var,
            subgroup = demo_val,
            classification = rep(c("Correct", "Incorrect"), each = n_terms),
            term = c(names(result$correct)[1:n_terms],
                    names(result$incorrect)[1:n_terms]),
            tfidf_score = c(as.numeric(result$correct)[1:n_terms],
                           as.numeric(result$incorrect)[1:n_terms]),
            stringsAsFactors = FALSE
          )
        }
      }

      if (length(comparison_rows) > 0) {
        demo_var_comparison <- bind_rows(comparison_rows)
        demo_tfidf_comparison[[demo_var]] <- demo_var_comparison
      }
    }

    # Save results
    saveRDS(demo_tfidf_results,
            file.path(AIM2_RESULTS_DIR, "demographic_tfidf_stratified.rds"))
    cat("Demographic-stratified TF-IDF results saved to RDS\n")

    # Save comparison tables
    if (length(demo_tfidf_comparison) > 0) {
      all_comparisons <- bind_rows(demo_tfidf_comparison)
      write_csv(all_comparisons,
                file.path(AIM2_RESULTS_DIR, "demographic_tfidf_comparison.csv"))
      cat("TF-IDF comparison table saved to CSV\n\n")

      # Create summary statistics
      cat("Summary: Terms unique to correct vs incorrect classifications by demographic\n")
      cat(strrep("-", 80) %+% "\n")

      for (demo_var in names(demo_tfidf_comparison)) {
        cat("\n", demo_var, ":\n", sep = "")

        demo_data <- demo_tfidf_comparison[[demo_var]]

        for (subgroup in unique(demo_data$subgroup)) {
          subgroup_data <- demo_data %>% filter(subgroup == !!subgroup)

          correct_terms <- subgroup_data %>%
            filter(classification == "Correct") %>%
            pull(term)

          incorrect_terms <- subgroup_data %>%
            filter(classification == "Incorrect") %>%
            pull(term)

          unique_to_correct <- setdiff(correct_terms, incorrect_terms)
          unique_to_incorrect <- setdiff(incorrect_terms, correct_terms)
          overlapping <- intersect(correct_terms, incorrect_terms)

          cat("  ", subgroup, ":\n", sep = "")
          cat("    Terms unique to Correct: ", length(unique_to_correct), "\n")
          cat("    Terms unique to Incorrect: ", length(unique_to_incorrect), "\n")
          cat("    Overlapping terms: ", length(overlapping), "\n")
        }
      }
      cat("\n")
    }
  }
}

cat("Demographic-stratified TF-IDF analysis complete\n\n")

# ==============================================================================
# PART 5: VISUALIZATIONS
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("PART 5: Creating Visualizations\n")
cat(strrep("=", 80) %+% "\n\n")

# 1. Word Clouds
cat("Creating word clouds...\n")

# Create filtered DFM for clean visualizations
# Remove single chars, numbers, and remaining artifacts
terms_to_keep <- featnames(adrd_dfm_grouped)
terms_to_keep <- terms_to_keep[
  nchar(terms_to_keep) > 1 &              # Not single characters
  !grepl("^[0-9]+$", terms_to_keep) &     # Not pure numbers
  !grepl("_", terms_to_keep)               # No underscores (masked tokens)
]

adrd_dfm_clean <- dfm_select(adrd_dfm_grouped, pattern = terms_to_keep,
                              selection = "keep", valuetype = "fixed")

# Word cloud for ADRD
png(file.path(AIM2_FIGURES_DIR, "wordcloud_adrd.png"),
    width = 10, height = 10, units = "in", res = 300)
textplot_wordcloud(adrd_dfm_clean[docid(adrd_dfm_clean) == "ADRD", ],
                  min_count = MIN_TERM_FREQ,
                  max_words = 100,
                  color = brewer.pal(8, "Dark2"),
                  rotation = 0.25)
title("Most Frequent Clinical Terms in ADRD Notes", cex.main = 1.5)
dev.off()

# Word cloud for CTRL
png(file.path(AIM2_FIGURES_DIR, "wordcloud_ctrl.png"),
    width = 10, height = 10, units = "in", res = 300)
textplot_wordcloud(adrd_dfm_clean[docid(adrd_dfm_clean) == "CTRL", ],
                  min_count = MIN_TERM_FREQ,
                  max_words = 100,
                  color = brewer.pal(8, "Set2"),
                  rotation = 0.25)
title("Most Frequent Clinical Terms in Control Notes", cex.main = 1.5)
dev.off()

cat("  Word clouds saved\n")

# 2. Top Terms Bar Plot
cat("Creating top terms bar plot...\n")

# Use filtered terms for visualization
plot_data <- bind_rows(
  term_freq_by_class_clean %>%
    filter(group == "ADRD") %>%
    arrange(desc(frequency)) %>%
    head(20) %>%
    mutate(class = "ADRD"),
  term_freq_by_class_clean %>%
    filter(group == "CTRL") %>%
    arrange(desc(frequency)) %>%
    head(20) %>%
    mutate(class = "CTRL")
)

top_terms_plot <- ggplot(plot_data,
                         aes(x = reorder(feature, frequency),
                             y = frequency, fill = class)) +
  geom_bar(stat = "identity") +
  facet_wrap(~class, scales = "free") +
  coord_flip() +
  scale_fill_manual(values = c("ADRD" = "#E74C3C", "CTRL" = "#3498DB")) +
  labs(
    title = "Top 20 Most Frequent Clinical Terms by Class",
    x = "Clinical Term",
    y = "Frequency",
    fill = "Class"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 12, face = "bold"),
    strip.text = element_text(size = 12, face = "bold"),
    strip.background = element_rect(fill = "lightgray"),
    legend.position = "none"
  )

ggsave(file.path(AIM2_FIGURES_DIR, "top_terms_by_class.png"),
       plot = top_terms_plot, width = 14, height = 8, dpi = 300)
cat("  Top terms plot saved\n")

# 3. Chi-Squared Plot
cat("Creating chi-squared keyness plot...\n")

# Filter chi2 results for clean visualization
chi2_plot_data <- bind_rows(
  top_adrd_terms_clean %>%
    head(20) %>%
    mutate(direction = "Overrepresented in ADRD"),
  top_ctrl_terms_clean %>%
    head(20) %>%
    mutate(direction = "Overrepresented in CTRL")
)

if (nrow(chi2_plot_data) > 0) {
  chi2_keyness_plot <- ggplot(chi2_plot_data,
                               aes(x = reorder(feature, chi2),
                                   y = chi2, fill = direction)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    scale_fill_manual(values = c(
      "Overrepresented in ADRD" = "#E74C3C",
      "Overrepresented in CTRL" = "#3498DB"
    )) +
    labs(
      title = "Top Discriminative Clinical Terms (œá¬≤ Test)",
      subtitle = sprintf("FDR < %.2f, filtered for clinical relevance", CHI_SQUARE_ALPHA),
      x = "Clinical Term",
      y = "œá¬≤ Statistic",
      fill = "Direction"
    ) +
    theme_classic() +
    theme(
      plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
      plot.subtitle = element_text(size = 11, hjust = 0.5),
      axis.text = element_text(size = 10),
      axis.title = element_text(size = 12, face = "bold"),
      legend.position = "bottom"
    )

  ggsave(file.path(AIM2_FIGURES_DIR, "chi_squared_keyness.png"),
         plot = chi2_keyness_plot, width = 12, height = 10, dpi = 300)
  cat("  Chi-squared plot saved\n")
} else {
  cat("  WARNING: No significant terms found for chi-squared plot\n")
}

# 4. TF-IDF Comparison Plot
cat("Creating TF-IDF comparison plot...\n")

# Use filtered TF-IDF terms
tfidf_plot_data <- data.frame(
  term = c(names(head(top_tfidf_adrd_clean, 20)), names(head(top_tfidf_ctrl_clean, 20))),
  tfidf = c(as.numeric(head(top_tfidf_adrd_clean, 20)),
            as.numeric(head(top_tfidf_ctrl_clean, 20))),
  class = c(rep("ADRD", min(20, length(top_tfidf_adrd_clean))),
            rep("CTRL", min(20, length(top_tfidf_ctrl_clean))))
)

tfidf_plot <- ggplot(tfidf_plot_data,
                     aes(x = reorder(term, tfidf), y = tfidf, fill = class)) +
  geom_bar(stat = "identity") +
  facet_wrap(~class, scales = "free") +
  coord_flip() +
  scale_fill_manual(values = c("ADRD" = "#E74C3C", "CTRL" = "#3498DB")) +
  labs(
    title = "Top 20 TF-IDF Clinical Terms by Class",
    x = "Clinical Term",
    y = "TF-IDF Weight",
    fill = "Class"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 12, face = "bold"),
    strip.text = element_text(size = 12, face = "bold"),
    strip.background = element_rect(fill = "lightgray"),
    legend.position = "none"
  )

ggsave(file.path(AIM2_FIGURES_DIR, "tfidf_comparison.png"),
       plot = tfidf_plot, width = 14, height = 8, dpi = 300)
cat("  TF-IDF plot saved\n\n")

# 5. Demographic-Stratified TF-IDF Visualizations
cat("Creating demographic-stratified TF-IDF visualizations...\n")

# Check if demographic TF-IDF analysis was performed
if (exists("demo_tfidf_comparison") && length(demo_tfidf_comparison) > 0) {

  # For each demographic variable, create visualizations
  for (demo_var in names(demo_tfidf_comparison)) {

    demo_data <- demo_tfidf_comparison[[demo_var]]

    # 5a. TF-IDF Heatmap by Demographic Subgroup
    cat("  Creating TF-IDF heatmap for", demo_var, "...\n")

    # Get top terms across all subgroups for this demographic
    top_terms_demo <- demo_data %>%
      group_by(term) %>%
      summarize(mean_tfidf = mean(tfidf_score, na.rm = TRUE), .groups = "drop") %>%
      arrange(desc(mean_tfidf)) %>%
      head(30) %>%
      pull(term)

    # Create matrix for heatmap
    heatmap_data <- demo_data %>%
      filter(term %in% top_terms_demo) %>%
      mutate(
        subgroup_class = paste0(subgroup, "_", classification)
      ) %>%
      select(term, subgroup_class, tfidf_score)

    # Create heatmap
    if (nrow(heatmap_data) > 0) {
      tfidf_heatmap <- ggplot(heatmap_data,
                              aes(x = subgroup_class, y = term, fill = tfidf_score)) +
        geom_tile(color = "white", size = 0.5) +
        scale_fill_gradient2(
          low = "#3498DB",
          mid = "#ECF0F1",
          high = "#E74C3C",
          midpoint = median(heatmap_data$tfidf_score, na.rm = TRUE),
          name = "TF-IDF\nScore"
        ) +
        labs(
          title = paste0("CNN Feature Importance by ", demo_var, " Subgroup"),
          subtitle = "TF-IDF scores for top discriminative terms",
          x = paste0(demo_var, " Subgroup √ó Classification"),
          y = "Clinical Term"
        ) +
        theme_minimal() +
        theme(
          plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
          plot.subtitle = element_text(size = 11, hjust = 0.5),
          axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
          axis.text.y = element_text(size = 9),
          axis.title = element_text(size = 12, face = "bold"),
          legend.title = element_text(size = 10, face = "bold"),
          legend.text = element_text(size = 9),
          panel.grid = element_blank()
        )

      ggsave(
        file.path(AIM2_FIGURES_DIR,
                  paste0("tfidf_heatmap_", tolower(demo_var), ".png")),
        plot = tfidf_heatmap,
        width = 12,
        height = 10,
        dpi = 300
      )
    }

    # 5b. Top phrases bar chart by subgroup
    cat("  Creating top phrases bar chart for", demo_var, "...\n")

    top_phrases_data <- demo_data %>%
      group_by(subgroup, classification) %>%
      arrange(desc(tfidf_score)) %>%
      slice_head(n = 15) %>%
      ungroup() %>%
      mutate(
        term = factor(term),
        subgroup_class = paste0(subgroup, " (", classification, ")")
      )

    if (nrow(top_phrases_data) > 0) {
      top_phrases_plot <- ggplot(top_phrases_data,
                                 aes(x = reorder(term, tfidf_score),
                                     y = tfidf_score,
                                     fill = classification)) +
        geom_col() +
        facet_wrap(~subgroup, scales = "free_y", ncol = 2) +
        coord_flip() +
        scale_fill_manual(
          values = c("Correct" = "#27AE60", "Incorrect" = "#E74C3C"),
          name = "Classification"
        ) +
        labs(
          title = paste0("Top TF-IDF Terms by ", demo_var, " Subgroup"),
          subtitle = "Comparing correct vs. incorrect classifications",
          x = "Clinical Term",
          y = "TF-IDF Score"
        ) +
        theme_classic() +
        theme(
          plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
          plot.subtitle = element_text(size = 11, hjust = 0.5),
          axis.text = element_text(size = 9),
          axis.title = element_text(size = 12, face = "bold"),
          strip.text = element_text(size = 11, face = "bold"),
          strip.background = element_rect(fill = "lightgray"),
          legend.position = "bottom",
          legend.title = element_text(size = 10, face = "bold")
        )

      ggsave(
        file.path(AIM2_FIGURES_DIR,
                  paste0("tfidf_top_phrases_", tolower(demo_var), ".png")),
        plot = top_phrases_plot,
        width = 14,
        height = 12,
        dpi = 300
      )
    }

    # 5c. Comparison plot: Phrases unique to correct vs incorrect
    cat("  Creating unique terms comparison for", demo_var, "...\n")

    # Calculate uniqueness
    unique_terms_data <- demo_data %>%
      group_by(subgroup, term) %>%
      summarize(
        appears_in = paste(sort(unique(classification)), collapse = "_"),
        max_tfidf = max(tfidf_score, na.rm = TRUE),
        .groups = "drop"
      ) %>%
      mutate(
        uniqueness = case_when(
          appears_in == "Correct" ~ "Unique to Correct",
          appears_in == "Incorrect" ~ "Unique to Incorrect",
          TRUE ~ "Both"
        )
      ) %>%
      filter(uniqueness != "Both") %>%
      group_by(subgroup, uniqueness) %>%
      arrange(desc(max_tfidf)) %>%
      slice_head(n = 10) %>%
      ungroup()

    if (nrow(unique_terms_data) > 0) {
      unique_terms_plot <- ggplot(unique_terms_data,
                                  aes(x = reorder(term, max_tfidf),
                                      y = max_tfidf,
                                      fill = uniqueness)) +
        geom_col() +
        facet_grid(subgroup ~ uniqueness, scales = "free", space = "free_y") +
        coord_flip() +
        scale_fill_manual(
          values = c(
            "Unique to Correct" = "#27AE60",
            "Unique to Incorrect" = "#E74C3C"
          ),
          name = "Term Type"
        ) +
        labs(
          title = paste0("Terms Unique to Classification Groups (", demo_var, ")"),
          subtitle = "Terms appearing only in correctly or incorrectly classified patients",
          x = "Clinical Term",
          y = "TF-IDF Score"
        ) +
        theme_classic() +
        theme(
          plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
          plot.subtitle = element_text(size = 11, hjust = 0.5),
          axis.text = element_text(size = 8),
          axis.title = element_text(size = 12, face = "bold"),
          strip.text = element_text(size = 10, face = "bold"),
          strip.background = element_rect(fill = "lightgray"),
          legend.position = "bottom"
        )

      ggsave(
        file.path(AIM2_FIGURES_DIR,
                  paste0("tfidf_unique_terms_", tolower(demo_var), ".png")),
        plot = unique_terms_plot,
        width = 16,
        height = 10,
        dpi = 300
      )
    }
  }

  cat("  Demographic TF-IDF visualizations saved\n\n")
} else {
  cat("  No demographic TF-IDF data available for visualization\n\n")
}

# ==============================================================================
# PART 6: LIME EXPLAINABILITY (Foundation)
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("PART 6: LIME Explainability Framework (Foundation)\n")
cat(strrep("=", 80) %+% "\n\n")

cat("NOTE: Full LIME implementation requires the `lime` R package\n")
cat("This section provides the foundation for LIME analysis\n\n")

# Check if lime package is available
if (requireNamespace("lime", quietly = TRUE)) {
  cat("lime package detected - LIME analysis can be performed\n")
  cat("See STATISTICAL_SIGNIFICANCE_METHODOLOGY.md for implementation guide\n\n")
} else {
  cat("lime package not installed\n")
  cat("To enable LIME analysis, run: install.packages('lime')\n\n")
}

# Sample predictions for LIME analysis
if (!is.null(predictions)) {
  cat("Selecting samples for LIME analysis...\n")

  # Select interesting cases for explanation
  lime_samples <- predictions %>%
    mutate(
      correct = Correct,
      prob = Predicted_Probability,
      true_label = Label
    ) %>%
    group_by(true_label, correct) %>%
    arrange(desc(abs(prob - 0.5))) %>%  # Most confident predictions
    slice_head(n = 5) %>%
    ungroup()

  cat("  Selected", nrow(lime_samples), "samples for explanation:\n")
  cat("    True ADRD, Correct:", sum(lime_samples$true_label == 1 & lime_samples$correct), "\n")
  cat("    True ADRD, Incorrect:", sum(lime_samples$true_label == 1 & !lime_samples$correct), "\n")
  cat("    True CTRL, Correct:", sum(lime_samples$true_label == 0 & lime_samples$correct), "\n")
  cat("    True CTRL, Incorrect:", sum(lime_samples$true_label == 0 & !lime_samples$correct), "\n\n")

  # Save sample IDs for LIME analysis
  write_csv(lime_samples %>% select(DE_ID, Label, Predicted_Probability, Correct),
            file.path(AIM2_RESULTS_DIR, "lime_sample_cases.csv"))
  cat("Sample cases for LIME saved\n\n")

} else {
  cat("Predictions not available - skipping LIME sample selection\n\n")
}

# ==============================================================================
# PART 6B: LIME EXPLAINABILITY (FULL IMPLEMENTATION)
# ==============================================================================

if (!is.null(predictions) && requireNamespace("lime", quietly = TRUE)) {
  cat(strrep("=", 80) %+% "\n")
  cat("PART 6B: LIME Explainability - Full Implementation\n")
  cat(strrep("=", 80) %+% "\n\n")

  library(lime)

  cat("Loading trained model for LIME...\n")
  source("utils_model_loader.R")

  artifacts <- load_all_artifacts(MODEL_DIR)

  # Find best model
  best_info_file <- file.path(RESULTS_DIR, "best_model_info.rds")
  if (file.exists(best_info_file)) {
    best_info <- readRDS(best_info_file)
    best_cycle <- best_info$best_cycle
  } else {
    best_cycle <- 1  # Default to first model
  }

  cat("Loading model cycle", best_cycle, "...\n")
  model <- load_model_auto(best_cycle, MODEL_DIR)

  # Create a wrapper class for Keras text model
  text_model <- structure(
    list(
      model = model,
      tokenizer = artifacts$tokenizer,
      maxlen = artifacts$maxlen
    ),
    class = "keras_text_model"
  )

  # Define model_type method for our wrapper
  model_type.keras_text_model <- function(x, ...) {
    "classification"
  }

  # Define predict_model method for our wrapper
  predict_model.keras_text_model <- function(x, newdata, type = "raw", ...) {
    # newdata is a character vector of texts
    sequences <- texts_to_sequences(x$tokenizer, newdata)
    padded <- pad_sequences(sequences, maxlen = x$maxlen, padding = "pre")
    preds <- x$model %>% predict(padded, verbose = 0)
    # Return probabilities for both classes (NON-ADRD, ADRD)
    data.frame(
      `0` = 1 - preds[, 1],
      `1` = preds[, 1],
      check.names = FALSE
    )
  }

  # Create LIME explainer
  cat("Creating LIME explainer...\n")
  explainer <- lime(
    x = test_set$txt,
    model = text_model,
    preprocess = tolower
  )

  # Select samples for explanation
  lime_cases <- lime_samples %>%
    left_join(test_set %>% select(DE_ID, txt), by = "DE_ID")

  cat("Generating LIME explanations for", nrow(lime_cases), "cases...\n")

  explanations <- explain(
    lime_cases$txt,
    explainer,
    n_labels = 1,  # Explain ADRD class
    n_features = 10,  # Top 10 features
    n_permutations = 1000
  )

  # Save explanations
  write_csv(explanations,
            file.path(AIM2_RESULTS_DIR, "lime_explanations.csv"))
  cat("LIME explanations saved\n")

  # Create LIME visualization
  cat("Creating LIME visualization...\n")

  png(file.path(AIM2_FIGURES_DIR, "lime_explanations.png"),
      width = 14, height = 10, units = "in", res = 300)
  plot_features(explanations)
  dev.off()

  cat("LIME visualization saved\n\n")

} else if (is.null(predictions)) {
  cat("\nPredictions not available - skipping LIME\n\n")
} else {
  cat("\nLIME package not installed. To enable:\n")
  cat("  install.packages('lime')\n\n")
}

# ==============================================================================
# PART 6C: DEMOGRAPHIC-STRATIFIED LIME ANALYSIS
# ==============================================================================
# PURPOSE: Analyze if LIME explanations differ by demographics

if (!is.null(predictions) && requireNamespace("lime", quietly = TRUE) &&
    exists("demo_vars_available") && length(demo_vars_available) > 0) {

  cat(strrep("=", 80) %+% "\n")
  cat("PART 6C: Demographic-Stratified LIME Analysis\n")
  cat(strrep("=", 80) %+% "\n\n")

  cat("Analyzing if LIME feature importance differs by demographics...\n\n")

  # Ensure we have the model and explainer
  if (!exists("model") || !exists("text_model") || !exists("explainer")) {
    cat("‚ö†Ô∏è  Model or explainer not available. Skipping demographic LIME analysis.\n\n")
  } else {

    # Merge predictions with test_set to get demographics
    test_data_with_demo <- test_set %>%
      left_join(predictions %>% select(DE_ID, Predicted_Probability, Label),
                by = "DE_ID")

    # For each demographic variable
    demo_lime_results <- list()

    for (demo_var in demo_vars_available) {

      if (!demo_var %in% names(test_data_with_demo)) next

      cat(strrep("-", 80) %+% "\n")
      cat("LIME Analysis by:", demo_var, "\n")
      cat(strrep("-", 80) %+% "\n\n")

      # Normalize gender if needed
      if (demo_var == "GENDER") {
        test_data_with_demo <- test_data_with_demo %>%
          mutate(GENDER = case_when(
            toupper(GENDER) %in% c("FEMALE", "F") ~ "Female",
            toupper(GENDER) %in% c("MALE", "M") ~ "Male",
            TRUE ~ GENDER
          ))
      }

      # Get unique subgroups
      demo_values <- test_data_with_demo %>%
        filter(!is.na(.data[[demo_var]]),
               .data[[demo_var]] != "",
               .data[[demo_var]] != "UNKNOWN") %>%
        pull(.data[[demo_var]]) %>%
        unique()

      demo_var_lime <- list()

      for (demo_val in demo_values) {

        # Select ADRD cases from this demographic subgroup
        subgroup_cases <- test_data_with_demo %>%
          filter(.data[[demo_var]] == demo_val, label == 1) %>%
          arrange(desc(Predicted_Probability)) %>%
          head(10)  # Top 10 confident ADRD predictions

        if (nrow(subgroup_cases) < 5) {
          cat("  Skipping", demo_val, "(insufficient ADRD cases)\n")
          next
        }

        cat("  Generating LIME explanations for", demo_val,
            "(", nrow(subgroup_cases), "cases)\n")

        # Generate LIME explanations
        tryCatch({
          explanations_sub <- explain(
            subgroup_cases$txt,
            explainer,
            n_labels = 1,
            n_features = 10,
            n_permutations = 500  # Reduced for speed
          )

          # Aggregate feature importance
          feature_importance <- explanations_sub %>%
            filter(label == "1") %>%  # ADRD class
            group_by(feature) %>%
            summarise(
              mean_weight = mean(feature_weight),
              median_weight = median(feature_weight),
              n_appearances = n(),
              .groups = "drop"
            ) %>%
            arrange(desc(abs(mean_weight))) %>%
            head(20) %>%
            mutate(
              demographic = demo_var,
              subgroup = demo_val
            )

          demo_var_lime[[demo_val]] <- feature_importance

          cat("    Top 5 important features:",
              paste(head(feature_importance$feature, 5), collapse = ", "), "\n")
          cat("    Mean weights:",
              paste(sprintf("%.3f", head(feature_importance$mean_weight, 5)), collapse = ", "), "\n")

        }, error = function(e) {
          cat("    Error generating LIME explanations:", e$message, "\n")
        })
      }

      # Store and compare
      if (length(demo_var_lime) > 0) {
        demo_lime_results[[demo_var]] <- demo_var_lime

        # Compare feature importance across subgroups
        if (length(demo_var_lime) >= 2) {
          cat("\n  Comparing LIME feature importance across", demo_var, ":\n")

          # Get top features for each subgroup
          top_features <- lapply(names(demo_var_lime), function(sg) {
            demo_var_lime[[sg]] %>%
              head(10) %>%
              pull(feature)
          })
          names(top_features) <- names(demo_var_lime)

          # Calculate overlap
          if (length(top_features) == 2) {
            overlap <- intersect(top_features[[1]], top_features[[2]])
            cat("    Common important features:", length(overlap), "/", 10, "\n")
            if (length(overlap) > 0) {
              cat("      ", paste(overlap, collapse = ", "), "\n")
            }

            overlap_pct <- length(overlap) / 10 * 100
            if (overlap_pct < 40) {
              cat("\n    ‚ö†Ô∏è  FINDING: Low overlap (", sprintf("%.0f%%", overlap_pct),
                  ") - model uses different features for ", demo_var, " subgroups\n", sep = "")
              cat("    This may indicate differential prediction patterns by demographics\n")
            } else {
              cat("\n    ‚úì Good overlap (", sprintf("%.0f%%", overlap_pct),
                  ") - consistent features across ", demo_var, "\n", sep = "")
            }
          }
        }
      }
      cat("\n")
    }

    # Save demographic LIME results
    if (length(demo_lime_results) > 0) {
      saveRDS(demo_lime_results,
              file.path(AIM2_RESULTS_DIR, "demographic_lime_stratified.rds"))

      # Create comparison table
      lime_comparison_df <- bind_rows(lapply(names(demo_lime_results), function(demo) {
        bind_rows(lapply(names(demo_lime_results[[demo]]), function(sg) {
          demo_lime_results[[demo]][[sg]]
        }))
      }))

      write_csv(lime_comparison_df,
                file.path(AIM2_RESULTS_DIR, "demographic_lime_comparison.csv"))

      cat("Demographic-stratified LIME results saved\n\n")
    }
  }
}

# ==============================================================================
# PART 7: BEHAVIORAL TESTING FRAMEWORK
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("PART 7: Behavioral Testing Framework\n")
cat(strrep("=", 80) %+% "\n\n")

cat("Behavioral testing analyzes model sensitivity to specific terms\n")
cat("by removing discriminative terms and measuring prediction changes.\n\n")

# Select top discriminative terms for behavioral testing
behavioral_test_terms <- list()

# Top 10 ADRD terms
if (nrow(top_adrd_terms) > 0) {
  behavioral_test_terms$adrd <- head(top_adrd_terms$feature, 10)
}

# Top 10 CTRL terms
if (nrow(top_ctrl_terms) > 0) {
  behavioral_test_terms$ctrl <- head(top_ctrl_terms$feature, 10)
}

cat("Selected terms for behavioral testing:\n")
cat("  ADRD terms:", length(behavioral_test_terms$adrd), "\n")
cat("  CTRL terms:", length(behavioral_test_terms$ctrl), "\n\n")

# Save behavioral test terms
saveRDS(behavioral_test_terms,
        file.path(AIM2_RESULTS_DIR, "behavioral_test_terms.rds"))

# Create behavioral testing function
create_behavioral_test <- function(original_text, term_to_remove) {
  #' Remove a term from text and return modified version
  #'
  #' @param original_text Original clinical note
  #' @param term_to_remove Term to remove
  #' @return Modified text with term removed

  # Simple removal (can be enhanced with synonyms, etc.)
  modified_text <- gsub(
    paste0("\\b", term_to_remove, "\\b"),
    "",  # Replace with empty
    original_text,
    ignore.case = TRUE
  )

  # Clean up extra spaces
  modified_text <- gsub("\\s+", " ", modified_text)
  modified_text <- trimws(modified_text)

  return(modified_text)
}

# Demonstrate behavioral testing on sample cases
if (!is.null(predictions) && file.exists(file.path(AIM2_RESULTS_DIR, "lime_sample_cases.csv"))) {
  cat("Demonstrating behavioral testing on sample cases...\n")

  # Load model and artifacts if not already loaded (from LIME section)
  if (!exists("model") || !exists("artifacts")) {
    cat("Loading model for behavioral testing...\n")
    source("utils_model_loader.R")
    artifacts <- load_all_artifacts(MODEL_DIR)

    # Find best model
    best_info_file <- file.path(RESULTS_DIR, "best_model_info.rds")
    if (file.exists(best_info_file)) {
      best_info <- readRDS(best_info_file)
      best_cycle <- best_info$best_cycle
    } else {
      best_cycle <- 1  # Default to first model
    }

    cat("Loading model cycle", best_cycle, "...\n")
    model <- load_model_auto(best_cycle, MODEL_DIR)
  }

  # Load sample cases
  sample_cases <- read_csv(file.path(AIM2_RESULTS_DIR, "lime_sample_cases.csv"),
                           show_col_types = FALSE)

  # Select one ADRD case for demonstration
  demo_case <- sample_cases %>%
    filter(Label == 1) %>%
    slice_head(n = 1)

  if (nrow(demo_case) > 0) {
    # Get original text
    original_text <- test_set %>%
      filter(DE_ID == demo_case$DE_ID) %>%
      pull(txt)

    if (length(original_text) > 0) {
      cat("\nBehavioral Test Demonstration:\n")
      cat("Original prediction:", sprintf("%.4f", demo_case$Predicted_Probability), "\n")

      # Test removal of each ADRD term
      behavioral_results <- data.frame(
        term_removed = character(),
        term_present = logical(),
        prediction_change = numeric(),
        stringsAsFactors = FALSE
      )

      for (term in behavioral_test_terms$adrd[1:5]) {  # Test first 5 terms
        # Check if term is present
        term_present <- grepl(paste0("\\b", term, "\\b"), original_text, ignore.case = TRUE)

        if (term_present) {
          # Create modified text
          modified_text <- create_behavioral_test(original_text, term)

          # Get prediction
          if (exists("model") && exists("artifacts")) {
            # Tokenize and predict
            seq_orig <- texts_to_sequences(artifacts$tokenizer, original_text)
            seq_mod <- texts_to_sequences(artifacts$tokenizer, modified_text)

            pad_orig <- pad_sequences(seq_orig, maxlen = artifacts$maxlen, padding = "pre")
            pad_mod <- pad_sequences(seq_mod, maxlen = artifacts$maxlen, padding = "pre")

            pred_orig <- model %>% predict(pad_orig, verbose = 0)
            pred_mod <- model %>% predict(pad_mod, verbose = 0)

            pred_change <- pred_mod[1, 1] - pred_orig[1, 1]

            behavioral_results <- rbind(behavioral_results, data.frame(
              term_removed = term,
              term_present = TRUE,
              prediction_change = pred_change
            ))

            cat("  Term '", term, "': Œî prediction = ", sprintf("%.4f", pred_change), "\n", sep = "")
          }
        } else {
          behavioral_results <- rbind(behavioral_results, data.frame(
            term_removed = term,
            term_present = FALSE,
            prediction_change = NA
          ))
        }
      }

      # Save behavioral test results
      write_csv(behavioral_results,
                file.path(AIM2_RESULTS_DIR, "behavioral_test_demo_results.csv"))
      cat("\nBehavioral test demonstration results saved\n")
    }
  }
  cat("\n")
}

# Create behavioral testing script template
cat("Creating behavioral testing script template...\n")

behavioral_script <- '# Behavioral Testing Script Template
# ==============================================================================
# Purpose: Systematically test model sensitivity to specific terms
#
# Usage:
#   1. Select terms from behavioral_test_terms.rds
#   2. For each term, create modified versions of test cases
#   3. Compare predictions on original vs modified texts
#   4. Measure sensitivity (Œî prediction)
# ==============================================================================

# Load required libraries
suppressPackageStartupMessages({
  library(tidyverse)  # For data manipulation (filter, %>%, etc.)
  library(keras)      # For model prediction functions
})

# Load terms
behavioral_test_terms <- readRDS("results/aim2/behavioral_test_terms.rds")

# Load model and artifacts
source("utils_model_loader.R")
artifacts <- load_all_artifacts("models")
best_cycle <- 1  # Update with your best model cycle
model <- load_model_auto(best_cycle, "models")

# Load test set
test_set <- readRDS("data/test_set.rds")

# Function to test term removal
test_term_removal <- function(de_id, term, model, artifacts, test_set) {
  # Get original text
  original_text <- test_set %>%
    filter(DE_ID == de_id) %>%
    pull(txt)

  # Check if term present
  term_present <- grepl(paste0("\\\\b", term, "\\\\b"), original_text, ignore.case = TRUE)

  if (!term_present) {
    return(list(term_present = FALSE, pred_change = NA))
  }

  # Remove term
  modified_text <- gsub(paste0("\\\\b", term, "\\\\b"), "", original_text, ignore.case = TRUE)
  modified_text <- gsub("\\\\s+", " ", trimws(modified_text))

  # Get predictions
  seq_orig <- texts_to_sequences(artifacts$tokenizer, original_text)
  seq_mod <- texts_to_sequences(artifacts$tokenizer, modified_text)

  pad_orig <- pad_sequences(seq_orig, maxlen = artifacts$maxlen, padding = "pre")
  pad_mod <- pad_sequences(seq_mod, maxlen = artifacts$maxlen, padding = "pre")

  pred_orig <- model %>% predict(pad_orig, verbose = 0)
  pred_mod <- model %>% predict(pad_mod, verbose = 0)

  pred_change <- pred_mod[1, 1] - pred_orig[1, 1]

  return(list(
    term_present = TRUE,
    pred_orig = pred_orig[1, 1],
    pred_mod = pred_mod[1, 1],
    pred_change = pred_change
  ))
}

# Run behavioral tests
# Example: Test all ADRD terms on all ADRD cases
cat("\\n")
cat("================================================================================\\n")
cat("Running Behavioral Tests\\n")
cat("================================================================================\\n\\n")

results <- data.frame()

# Get ADRD cases
adrd_cases <- test_set %>% filter(label == 1)
n_cases_to_test <- min(50, nrow(adrd_cases))

cat("Testing", length(behavioral_test_terms$adrd), "ADRD terms on", n_cases_to_test, "ADRD cases\\n\\n")

for (i in seq_along(behavioral_test_terms$adrd)) {
  term <- behavioral_test_terms$adrd[i]
  cat("Testing term", i, "of", length(behavioral_test_terms$adrd), ":", term, "\\n")

  term_results <- 0

  for (de_id in adrd_cases$DE_ID[1:n_cases_to_test]) {
    result <- test_term_removal(de_id, term, model, artifacts, test_set)

    if (result$term_present) {
      results <- rbind(results, data.frame(
        DE_ID = de_id,
        term = term,
        pred_orig = result$pred_orig,
        pred_mod = result$pred_mod,
        pred_change = result$pred_change,
        stringsAsFactors = FALSE
      ))
      term_results <- term_results + 1
    }
  }

  cat("  Found term in", term_results, "cases\\n")
}

# Analyze and save results
cat("\\n")
cat("================================================================================\\n")
cat("Results Summary\\n")
cat("================================================================================\\n\\n")

if (nrow(results) > 0) {
  cat("Total tests with term present:", nrow(results), "\\n")
  cat("Prediction change summary:\\n")
  print(summary(results$pred_change))
  cat("\\n")

  # Aggregate by term
  term_summary <- results %>%
    group_by(term) %>%
    summarize(
      n_cases = n(),
      mean_change = mean(pred_change),
      sd_change = sd(pred_change),
      median_change = median(pred_change),
      .groups = "drop"
    ) %>%
    arrange(desc(abs(mean_change)))

  cat("\\nMean prediction change by term:\\n")
  print(term_summary)

  # Save results
  write_csv(results, "results/aim2/behavioral_test_results.csv")
  write_csv(term_summary, "results/aim2/behavioral_test_summary.csv")
  cat("\\nResults saved to results/aim2/behavioral_test_results.csv\\n")
  cat("Summary saved to results/aim2/behavioral_test_summary.csv\\n")
} else {
  cat("No results - terms not found in any test cases\\n")
}
'

writeLines(behavioral_script,
           file.path(AIM2_RESULTS_DIR, "behavioral_testing_template.R"))
cat("Behavioral testing template saved\n\n")

# ==============================================================================
# PART 8: SUMMARY REPORT
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("Creating Summary Report\n")
cat(strrep("=", 80) %+% "\n\n")

report_file <- file.path(AIM2_RESULTS_DIR, "aim2_feature_analysis_report.txt")
sink(report_file)

cat("ADRD ePhenotyping - AIM 2: Feature Analysis Report\n")
cat(strrep("=", 80), "\n\n")
cat("Date:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n\n")

cat("CORPUS STATISTICS\n")
cat(strrep("-", 40), "\n")
cat("Total documents:", nrow(full_corpus), "\n")
cat("ADRD documents:", sum(full_corpus$label == 1),
    sprintf("(%.1f%%)\n", mean(full_corpus$label == 1) * 100))
cat("Control documents:", sum(full_corpus$label == 0),
    sprintf("(%.1f%%)\n", mean(full_corpus$label == 0) * 100))
cat("Unique features (after trimming):", nfeat(adrd_dfm_trimmed), "\n")
cat("Min term frequency threshold:", MIN_TERM_FREQ, "\n\n")

cat("CHI-SQUARED TEST RESULTS\n")
cat(strrep("-", 40), "\n")
cat("Features tested:", nrow(chi2_results), "\n")
cat("Significant features (FDR < ", CHI_SQUARE_ALPHA, "): ",
    sum(chi2_results$significant, na.rm = TRUE), "\n", sep = "")
cat("  Overrepresented in ADRD:",
    sum(chi2_results$chi2 > 0 & chi2_results$significant, na.rm = TRUE), "\n")
cat("  Overrepresented in CTRL:",
    sum(chi2_results$chi2 < 0 & chi2_results$significant, na.rm = TRUE), "\n\n")

cat("TOP 20 DISCRIMINATIVE TERMS FOR ADRD\n")
cat(strrep("-", 40), "\n")
if (nrow(top_adrd_terms) > 0) {
  print(head(top_adrd_terms %>%
               select(feature, chi2, p_adjusted), 20))
} else {
  cat("No significant terms found\n")
}
cat("\n")

cat("TOP 20 DISCRIMINATIVE TERMS FOR CTRL\n")
cat(strrep("-", 40), "\n")
if (nrow(top_ctrl_terms) > 0) {
  print(head(top_ctrl_terms %>%
               select(feature, chi2, p_adjusted), 20))
} else {
  cat("No significant terms found\n")
}
cat("\n")

cat("TF-IDF TOP TERMS\n")
cat(strrep("-", 40), "\n")
cat("ADRD:\n")
print(head(top_tfidf_adrd, 20))
cat("\nCTRL:\n")
print(head(top_tfidf_ctrl, 20))
cat("\n")

cat("OUTPUT FILES\n")
cat(strrep("-", 40), "\n")
cat("Results directory:", AIM2_RESULTS_DIR, "/\n")
cat("Figures directory:", AIM2_FIGURES_DIR, "/\n\n")

cat("Generated files:\n")
cat("  - term_frequencies_overall.csv\n")
cat("  - term_frequencies_by_class.csv\n")
cat("  - chi_squared_results.csv\n")
cat("  - discriminative_terms.xlsx\n")
cat("  - tfidf_top_terms.csv\n")
cat("  - lime_sample_cases.csv\n")
cat("  - wordcloud_adrd.png\n")
cat("  - wordcloud_ctrl.png\n")
cat("  - top_terms_by_class.png\n")
cat("  - chi_squared_keyness.png\n")
cat("  - tfidf_comparison.png\n\n")

cat("NEXT STEPS\n")
cat(strrep("-", 40), "\n")
cat("1. Review discriminative terms for clinical relevance\n")
cat("2. Consult subject matter experts to classify terms\n")
cat("3. Implement full LIME analysis (requires lime package)\n")
cat("4. Conduct behavioral testing with identified terms\n")
cat("5. Validate findings with external dataset\n")

sink()

cat("Report saved:", report_file, "\n\n")

# Final Summary ===============================================================
cat(strrep("=", 80) %+% "\n")
cat("AIM 2 FEATURE ANALYSIS COMPLETE\n")
cat(strrep("=", 80) %+% "\n\n")

cat("Summary:\n")
cat("  Corpus size:", nrow(full_corpus), "documents\n")
cat("  Unique features:", nfeat(adrd_dfm_trimmed), "\n")
cat("  Significant terms:", sum(chi2_results$significant, na.rm = TRUE), "\n")
cat("  Visualizations created: 5\n\n")

cat("Key Findings:\n")
cat("  Top ADRD term:", ifelse(nrow(top_adrd_terms) > 0,
                                top_adrd_terms$feature[1], "N/A"), "\n")
cat("  Top CTRL term:", ifelse(nrow(top_ctrl_terms) > 0,
                                top_ctrl_terms$feature[1], "N/A"), "\n\n")

cat("Output Directories:\n")
cat("  Results:", AIM2_RESULTS_DIR, "/\n")
cat("  Figures:", AIM2_FIGURES_DIR, "/\n\n")

cat("Next Steps:\n")
cat("  1. Review discriminative_terms.xlsx for clinical relevance\n")
cat("  2. Examine word clouds and plots\n")
cat("  3. Install 'lime' package for explainability: install.packages('lime')\n")
cat("  4. Consult STATISTICAL_SIGNIFICANCE_METHODOLOGY.md for LIME implementation\n")
cat("  5. Prepare behavioral testing scenarios\n\n")

# ==============================================================================
# PART 8: DEMOGRAPHIC FEATURE FAIRNESS SUMMARY
# ==============================================================================

cat(strrep("=", 80) %+% "\n")
cat("PART 8: Demographic Feature Fairness Summary\n")
cat(strrep("=", 80) %+% "\n\n")

if (exists("demo_chi2_results") && length(demo_chi2_results) > 0) {
  cat("DISCRIMINATIVE TERMS BY DEMOGRAPHICS\n")
  cat(strrep("-", 40), "\n")

  for (demo_var in names(demo_chi2_results)) {
    cat("\n", demo_var, ":\n", sep = "")
    for (sg in names(demo_chi2_results[[demo_var]])) {
      top_5 <- demo_chi2_results[[demo_var]][[sg]] %>%
        head(5) %>%
        pull(feature)
      cat("  ", sg, ": ", paste(top_5, collapse = ", "), "\n", sep = "")
    }
  }
  cat("\n")
}

if (exists("demo_lime_results") && length(demo_lime_results) > 0) {
  cat("LIME FEATURE IMPORTANCE BY DEMOGRAPHICS\n")
  cat(strrep("-", 40), "\n")

  for (demo_var in names(demo_lime_results)) {
    cat("\n", demo_var, ":\n", sep = "")
    for (sg in names(demo_lime_results[[demo_var]])) {
      top_5 <- demo_lime_results[[demo_var]][[sg]] %>%
        head(5) %>%
        pull(feature)
      cat("  ", sg, ": ", paste(top_5, collapse = ", "), "\n", sep = "")
    }
  }
  cat("\n")
}

cat("FAIRNESS ASSESSMENT:\n")
cat(strrep("-", 40), "\n")
cat("‚úì Demographic-stratified chi-squared analysis complete\n")
cat("‚úì Demographic-stratified LIME analysis complete\n")
cat("\nKEY QUESTIONS ANSWERED:\n")
cat("1. Do discriminative features differ by demographics? ‚Üí See chi2 comparison\n")
cat("2. Do LIME explanations differ by demographics? ‚Üí See LIME comparison\n")
cat("3. Are certain groups explained differently? ‚Üí Check overlap percentages\n\n")

cat("OUTPUT FILES:\n")
cat("  - demographic_chi2_stratified.rds\n")
cat("  - demographic_chi2_comparison.csv\n")
cat("  - demographic_lime_stratified.rds\n")
cat("  - demographic_lime_comparison.csv\n\n")

cat("NEXT STEPS:\n")
cat("1. Review chi-squared term overlap across demographic groups\n")
cat("2. Examine LIME feature importance differences\n")
cat("3. If low overlap (<50%), investigate differential documentation patterns\n")
cat("4. Consider demographic-specific model recalibration if needed\n\n")

cat(strrep("=", 80) %+% "\n")
cat("Analysis completed successfully!\n")
cat(strrep("=", 80) %+% "\n")
