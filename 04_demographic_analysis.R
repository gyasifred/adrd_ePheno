#!/usr/bin/env Rscript
# ==============================================================================
# ADRD ePhenotyping Pipeline - AIM 1: Demographic Fairness Analysis
# ==============================================================================
# Version: 2.0
# Author: Gyasi, Frederick
# Evaluation Using Jihad Obeid's Pre-Trained Models
#
# üéØ KEY: Uses predictions from Jihad's models (generated by 03_evaluate_models.R)
#
# Project: adrd_ephenotyping
# Aim 1: Evaluate model performance differences between demographic groups
#
# Purpose: Analyze CNN model performance across:
#   - Demographics (Gender, Race, Ethnicity, Age)
#   - Social Determinants (Insurance/Financial class if available)
#   - Intersectional groups (e.g., Gender x Race)
#   - Detect potential bias or fairness issues
#
# Statistical Testing (NEW in v2.0):
#   - Permutation testing (10,000 iterations)
#   - Bootstrap confidence intervals
#   - False Discovery Rate (FDR) correction
#   - Cohen's d effect sizes
#
# Inputs:  data/test_set.rds, results/predictions_df.csv
# Outputs: results/demographic/*, figures/demographic/*
# ==============================================================================

# Define operators FIRST
`%+%` <- function(a, b) paste0(a, b)

# Load Libraries ==============================================================
cat(strrep("=", 80) %+% "\n")
cat("ADRD ePhenotyping - Demographic Performance Analysis\n")
cat("Aim 1: Subgroup Performance Evaluation\n")
cat(strrep("=", 80) %+% "\n\n")

cat("Loading required libraries...\n")
suppressPackageStartupMessages({
  library(tidyverse)    # Data manipulation
  library(pROC)         # ROC analysis
  library(ggplot2)      # Visualization
  library(gridExtra)    # Multiple plots
  library(scales)       # Plot formatting
  library(writexl)      # Excel export
  library(broom)        # Statistical tests
  library(stringr)      # String manipulation
})

options(dplyr.summarise.inform = FALSE)

# Load Statistical Testing Utilities ==========================================
cat("Loading statistical testing utilities...\n")
source("utils_statistical_tests.R")
cat("\n")

# Configuration ===============================================================
cat("\nConfiguration:\n")
cat(strrep("-", 80) %+% "\n")

# Paths
DATA_DIR <- "data"
RESULTS_DIR <- "results"
FIGURES_DIR <- "figures"

# Create subdirectories for demographic results
DEMO_RESULTS_DIR <- file.path(RESULTS_DIR, "demographic")
DEMO_FIGURES_DIR <- file.path(FIGURES_DIR, "demographic")
dir.create(DEMO_RESULTS_DIR, showWarnings = FALSE, recursive = TRUE)
dir.create(DEMO_FIGURES_DIR, showWarnings = FALSE, recursive = TRUE)

# Analysis parameters
OPTIMAL_THRESHOLD <- 0.5        # Classification threshold
CONFIDENCE_LEVEL <- 0.95        # For confidence intervals
MIN_SUBGROUP_SIZE <- 10         # Minimum samples for subgroup analysis

# Statistical testing parameters
N_PERMUTATIONS <- 10000         # Number of permutations for significance tests
N_BOOTSTRAP <- 10000            # Number of bootstrap samples for CIs
FDR_ALPHA <- 0.05               # False discovery rate threshold
RUN_STATISTICAL_TESTS <- TRUE   # Enable/disable statistical tests

cat("  Classification threshold:", OPTIMAL_THRESHOLD, "\n")
cat("  Confidence level:", CONFIDENCE_LEVEL, "\n")
cat("  Minimum subgroup size:", MIN_SUBGROUP_SIZE, "\n")
if (RUN_STATISTICAL_TESTS) {
  cat("  Statistical testing: ENABLED\n")
  cat("    Permutations:", N_PERMUTATIONS, "\n")
  cat("    Bootstrap samples:", N_BOOTSTRAP, "\n")
  cat("    FDR alpha:", FDR_ALPHA, "\n")
}
cat("\n")

# Helper Functions ============================================================

# Simplify long categorical names for display purposes
simplify_category_name <- function(full_name) {
  # Vectorized version using sapply
  sapply(full_name, function(name) {
    # Handle NA
    if (is.na(name)) return("Unknown")

    # Convert to character
    name <- as.character(name)

    # RACE simplifications
    race_map <- c(
      "WHITE OR CAUCASIAN" = "White",
      "BLACK OR AFRICAN AMERICAN" = "Black",
      "OTHER ASIAN" = "Asian",
      "AMERICAN INDIAN OR ALASKA NATIVE" = "Am. Indian/AK Native",
      "NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER" = "Pacific Islander",
      "OTHER" = "Other",
      "UNKNOWN" = "Unknown",
      "PATIENT REFUSED" = "Refused"
    )

    # HISPANIC simplifications
    hispanic_map <- c(
      "NO, NOT HISPANIC OR LATINO" = "Non-Hispanic",
      "YES, ANOTHER HISPANIC OR LATINO" = "Hispanic",
      "YES, HISPANIC OR LATINO" = "Hispanic",
      "UNKNOWN" = "Unknown",
      "PATIENT REFUSED" = "Refused"
    )

    # Try race mapping
    if (name %in% names(race_map)) {
      return(race_map[name])
    }

    # Try hispanic mapping
    if (name %in% names(hispanic_map)) {
      return(hispanic_map[name])
    }

    # If no mapping found, try to shorten intelligently
    if (nchar(name) > 25) {
      # Take first 3 words
      words <- unlist(strsplit(name, " "))
      if (length(words) > 3) {
        return(paste(words[1:3], collapse = " "))
      }
    }

    return(name)
  }, USE.NAMES = FALSE)
}

# Wrap long text for plot labels
wrap_text <- function(text, width = 20) {
  sapply(text, function(x) {
    if (is.na(x)) return("Unknown")
    x <- as.character(x)
    # Use simplified name if available
    x <- simplify_category_name(x)
    # Wrap if still too long
    if (nchar(x) > width) {
      paste(strwrap(x, width = width), collapse = "\n")
    } else {
      x
    }
  }, USE.NAMES = FALSE)
}

# Perform chi-squared test for subgroup independence (IMPROVEMENT 3)
#' Tests H0: ADRD vs Control distribution is independent of demographic category
#' @param data Data frame containing labels and group variable
#' @param group_var Name of grouping variable (e.g., "GENDER")
#' @param label_var Name of outcome variable (default: "true_label")
#' @return List with test results, p-value, statistic, interpretation
perform_chi_squared_test <- function(data, group_var, label_var = "true_label") {

  # Filter to valid observations
  test_data <- data %>%
    filter(!is.na(.data[[group_var]]), !is.na(.data[[label_var]]))

  if (nrow(test_data) < 10) {
    return(list(
      test_type = "insufficient_data",
      p_value = NA_real_,
      statistic = NA_real_,
      df = NA_integer_,
      method = "Insufficient data",
      message = paste("Insufficient data: N =", nrow(test_data))
    ))
  }

  # Create contingency table
  cont_table <- table(test_data[[label_var]], test_data[[group_var]])

  # Remove categories with zero counts
  cont_table <- cont_table[, colSums(cont_table) > 0, drop = FALSE]
  cont_table <- cont_table[rowSums(cont_table) > 0, , drop = FALSE]

  if (ncol(cont_table) < 2 || nrow(cont_table) < 2) {
    return(list(
      test_type = "insufficient_categories",
      p_value = NA_real_,
      method = "Insufficient categories",
      message = "Fewer than 2 categories with data"
    ))
  }

  # Check expected frequencies for test selection
  chi_test <- chisq.test(cont_table)
  expected <- chi_test$expected

  # Use Fisher's exact if expected frequencies < 5
  if (any(expected < 5)) {
    fisher_result <- fisher.test(cont_table, simulate.p.value = TRUE, B = 10000)
    return(list(
      test_type = "fisher_exact",
      p_value = fisher_result$p.value,
      statistic = NA_real_,
      df = NA_integer_,
      method = "Fisher's Exact Test (simulated p-value)",
      table = cont_table,
      interpretation = ifelse(fisher_result$p.value < 0.05,
                             "ADRD vs Control distribution DIFFERS significantly by group",
                             "No significant difference in ADRD vs Control distribution by group")
    ))
  } else {
    return(list(
      test_type = "chi_squared",
      p_value = chi_test$p.value,
      statistic = as.numeric(chi_test$statistic),
      df = chi_test$parameter,
      method = "Pearson's Chi-squared test",
      table = cont_table,
      interpretation = ifelse(chi_test$p.value < 0.05,
                             "ADRD vs Control distribution DIFFERS significantly by group",
                             "No significant difference in ADRD vs Control distribution by group")
    ))
  }
}

# Calculate comprehensive metrics for a demographic subgroup
calculate_subgroup_metrics <- function(y_true, y_pred_prob,
                                      threshold = 0.5,
                                      conf_level = 0.95) {
  # Skip if too few samples
  if (length(y_true) < MIN_SUBGROUP_SIZE) {
    return(NULL)
  }
  
  y_pred_class <- ifelse(y_pred_prob >= threshold, 1, 0)
  
  # Confusion matrix
  tp <- sum(y_true == 1 & y_pred_class == 1)
  tn <- sum(y_true == 0 & y_pred_class == 0)
  fp <- sum(y_true == 0 & y_pred_class == 1)
  fn <- sum(y_true == 1 & y_pred_class == 0)
  
  # Basic metrics
  n <- length(y_true)
  n_pos <- sum(y_true == 1)
  n_neg <- sum(y_true == 0)
  
  accuracy <- (tp + tn) / n
  sensitivity <- ifelse(n_pos > 0, tp / (tp + fn), NA)
  specificity <- ifelse(n_neg > 0, tn / (tn + fp), NA)
  precision <- ifelse((tp + fp) > 0, tp / (tp + fp), NA)
  npv <- ifelse((tn + fn) > 0, tn / (tn + fn), NA)
  f1 <- ifelse(!is.na(precision) & !is.na(sensitivity) & 
               (precision + sensitivity) > 0,
               2 * (precision * sensitivity) / (precision + sensitivity), NA)
  
  # Positive prediction rate (for fairness metrics)
  ppr <- (tp + fp) / n
  
  # ROC and AUC
  tryCatch({
    roc_obj <- roc(y_true, y_pred_prob, 
                   levels = c(0, 1), 
                   direction = "<", 
                   quiet = TRUE)
    
    auc <- as.numeric(roc_obj$auc)
    auc_ci <- ci.auc(roc_obj, conf.level = conf_level)
    
    return(list(
      n = n,
      n_pos = n_pos,
      n_neg = n_neg,
      tp = tp, tn = tn, fp = fp, fn = fn,
      accuracy = accuracy,
      sensitivity = sensitivity,
      specificity = specificity,
      precision = precision,
      npv = npv,
      f1 = f1,
      ppr = ppr,
      auc = auc,
      auc_ci_lower = auc_ci[1],
      auc_ci_upper = auc_ci[3]
    ))
  }, error = function(e) {
    # If ROC fails, return metrics without AUC
    return(list(
      n = n,
      n_pos = n_pos,
      n_neg = n_neg,
      tp = tp, tn = tn, fp = fp, fn = fn,
      accuracy = accuracy,
      sensitivity = sensitivity,
      specificity = specificity,
      precision = precision,
      npv = npv,
      f1 = f1,
      ppr = ppr,
      auc = NA,
      auc_ci_lower = NA,
      auc_ci_upper = NA
    ))
  })
}

# Load Data ===================================================================
cat(strrep("=", 80) %+% "\n")
cat("Loading Data\n")
cat(strrep("=", 80) %+% "\n\n")

# Load test set
test_file <- file.path(DATA_DIR, "test_set.rds")
if (!file.exists(test_file)) {
  stop("Test data not found: ", test_file, 
       "\nPlease run 01_prepare_data.R first!")
}

test_set <- readRDS(test_file)
cat("Test set loaded:", nrow(test_set), "samples\n")

# Verify required columns
if (!"label" %in% names(test_set)) {
  stop("Column 'label' not found in test set!")
}

# Load predictions from evaluation script
pred_file <- file.path(RESULTS_DIR, "predictions_df.csv")
if (!file.exists(pred_file)) {
  stop("Predictions file not found: ", pred_file, 
       "\nPlease run 03_evaluate_models.R first!")
}

predictions <- read_csv(pred_file, show_col_types = FALSE)
cat("Predictions loaded:", nrow(predictions), "samples\n")

# Check column names in predictions
cat("\nPredictions file columns:\n")
cat("  ", paste(names(predictions), collapse = ", "), "\n\n")

# Merge test set with predictions
# Note: predictions_df.csv already has demographics if they were in test_set
# We'll use predictions as the primary source
analysis_data <- predictions %>%
  rename(
    true_label = Label,           # Label column from predictions (numeric 0/1)
    predicted_prob = Predicted_Probability,
    predicted_class = Predicted_Class
  ) %>%
  mutate(
    true_label = as.numeric(true_label)  # Ensure numeric
  )

cat("Analysis dataset prepared:", nrow(analysis_data), "samples\n")

# Normalize categorical values for consistent analysis (IMPROVEMENT 1)
cat("\nNormalizing categorical demographics...\n")
analysis_data <- analysis_data %>%
  mutate(
    # Gender normalization (FEMALE/F ‚Üí Female, MALE/M ‚Üí Male)
    GENDER = if("GENDER" %in% names(.)) {
      case_when(
        toupper(GENDER) %in% c("FEMALE", "F") ~ "Female",
        toupper(GENDER) %in% c("MALE", "M") ~ "Male",
        toupper(GENDER) == "UNKNOWN" ~ NA_character_,
        is.na(GENDER) ~ NA_character_,
        TRUE ~ GENDER
      )
    } else { GENDER },
    # Race normalization
    RACE = if("RACE" %in% names(.)) {
      case_when(
        is.na(RACE) | RACE == "" | toupper(RACE) == "UNKNOWN" ~ NA_character_,
        TRUE ~ RACE
      )
    } else { RACE },
    # Hispanic normalization
    HISPANIC = if("HISPANIC" %in% names(.)) {
      case_when(
        is.na(HISPANIC) | HISPANIC == "" | toupper(HISPANIC) == "UNKNOWN" ~ NA_character_,
        TRUE ~ HISPANIC
      )
    } else { HISPANIC }
  )

# Verify normalization
if ("GENDER" %in% names(analysis_data)) {
  cat("After gender normalization:\n")
  cat("  Gender values:", paste(unique(na.omit(analysis_data$GENDER)), collapse=", "), "\n")
}
cat("\n")

# Check for available demographic variables
available_demos <- c()
for (demo in c("GENDER", "RACE", "HISPANIC")) {
  if (demo %in% names(analysis_data)) {
    n_unique <- n_distinct(analysis_data[[demo]], na.rm = TRUE)
    n_valid <- sum(!is.na(analysis_data[[demo]]) &
                   analysis_data[[demo]] != "" &
                   analysis_data[[demo]] != "UNKNOWN")
    cat("  ", demo, ": ", n_unique, " unique values, ", n_valid, " valid\n", sep = "")
    available_demos <- c(available_demos, demo)
  }
}
cat("\n")

if (length(available_demos) == 0) {
  stop("No demographic variables found!\n",
       "Required: at least one of GENDER, RACE, HISPANIC in predictions file")
}

# Detect and standardize SDOH variables (IMPROVEMENT 2)
cat("Detecting Social Determinants of Health (SDOH) variables...\n")
sdoh_variables <- c()

# Insurance detection
insurance_cols <- c("INSURANCE", "INSURANCE_TYPE", "PAYER", "INSURANCE_CLASS")
if (any(insurance_cols %in% names(analysis_data))) {
  found_col <- intersect(insurance_cols, names(analysis_data))[1]
  analysis_data <- analysis_data %>%
    rename(INSURANCE = !!found_col) %>%
    mutate(INSURANCE = ifelse(INSURANCE == "" | toupper(INSURANCE) == "UNKNOWN",
                              NA_character_, INSURANCE))
  n_valid <- sum(!is.na(analysis_data$INSURANCE))
  cat("  INSURANCE:", n_distinct(analysis_data$INSURANCE, na.rm=TRUE),
      "categories,", n_valid, "valid\n")
  sdoh_variables <- c(sdoh_variables, "INSURANCE")
}

# Education detection
education_cols <- c("EDUCATION", "EDUCATION_LEVEL", "EDU_LEVEL", "EDUC")
if (any(education_cols %in% names(analysis_data))) {
  found_col <- intersect(education_cols, names(analysis_data))[1]
  analysis_data <- analysis_data %>%
    rename(EDUCATION = !!found_col) %>%
    mutate(EDUCATION = ifelse(EDUCATION == "" | toupper(EDUCATION) == "UNKNOWN",
                              NA_character_, EDUCATION))
  n_valid <- sum(!is.na(analysis_data$EDUCATION))
  cat("  EDUCATION:", n_distinct(analysis_data$EDUCATION, na.rm=TRUE),
      "categories,", n_valid, "valid\n")
  sdoh_variables <- c(sdoh_variables, "EDUCATION")
}

# Financial class detection
financial_cols <- c("FINANCIAL_CLASS", "FIN_CLASS", "PAYMENT_CLASS", "FINANCIAL_STATUS")
if (any(financial_cols %in% names(analysis_data))) {
  found_col <- intersect(financial_cols, names(analysis_data))[1]
  analysis_data <- analysis_data %>%
    rename(FINANCIAL_CLASS = !!found_col) %>%
    mutate(FINANCIAL_CLASS = ifelse(FINANCIAL_CLASS == "" | toupper(FINANCIAL_CLASS) == "UNKNOWN",
                                    NA_character_, FINANCIAL_CLASS))
  n_valid <- sum(!is.na(analysis_data$FINANCIAL_CLASS))
  cat("  FINANCIAL_CLASS:", n_distinct(analysis_data$FINANCIAL_CLASS, na.rm=TRUE),
      "categories,", n_valid, "valid\n")
  sdoh_variables <- c(sdoh_variables, "FINANCIAL_CLASS")
}

cat("\nSDOH variables found:",
    ifelse(length(sdoh_variables) > 0, paste(sdoh_variables, collapse=", "), "None"), "\n\n")

# Display category examples
cat("Categorical value examples:\n")
for (demo in available_demos) {
  unique_vals <- unique(na.omit(analysis_data[[demo]]))
  unique_vals <- unique_vals[unique_vals != "" & unique_vals != "UNKNOWN"]
  if (length(unique_vals) > 0 && length(unique_vals) <= 10) {
    cat("  ", demo, ":\n", sep = "")
    for (val in head(unique_vals, 5)) {
      val_char <- as.character(val)
      simplified <- simplify_category_name(val_char)
      if (nchar(val_char) > 25) {
        cat("    '", val_char, "' ‚Üí '", simplified, "'\n", sep = "")
      } else {
        cat("    '", val_char, "'\n", sep = "")
      }
    }
  }
}
cat("\n")

# Overall Performance =========================================================
cat(strrep("=", 80) %+% "\n")
cat("Overall Performance (Baseline)\n")
cat(strrep("=", 80) %+% "\n\n")

overall_metrics <- calculate_subgroup_metrics(
  analysis_data$true_label,
  analysis_data$predicted_prob,
  threshold = OPTIMAL_THRESHOLD,
  conf_level = CONFIDENCE_LEVEL
)

cat("Overall Test Set Performance:\n")
cat(strrep("-", 40), "\n")
cat("  N:", overall_metrics$n, "\n")
cat("  ADRD cases:", overall_metrics$n_pos, 
    sprintf("(%.1f%%)\n", overall_metrics$n_pos / overall_metrics$n * 100))
cat("  Control cases:", overall_metrics$n_neg,
    sprintf("(%.1f%%)\n", overall_metrics$n_neg / overall_metrics$n * 100))
cat("  AUC:", sprintf("%.4f", overall_metrics$auc))
if (!is.na(overall_metrics$auc_ci_lower)) {
  cat(sprintf(" (95%% CI: %.4f-%.4f)", 
              overall_metrics$auc_ci_lower, overall_metrics$auc_ci_upper))
}
cat("\n")
cat("  Accuracy:", sprintf("%.4f", overall_metrics$accuracy), "\n")
cat("  Sensitivity:", sprintf("%.4f", overall_metrics$sensitivity), "\n")
cat("  Specificity:", sprintf("%.4f", overall_metrics$specificity), "\n")
cat("  F1 Score:", sprintf("%.4f", overall_metrics$f1), "\n\n")

# Gender Analysis =============================================================
if ("GENDER" %in% available_demos) {
  cat(strrep("=", 80) %+% "\n")
  cat("Gender-Stratified Analysis\n")
  cat(strrep("=", 80) %+% "\n\n")
  
  # Show distribution
  gender_results <- analysis_data %>%
    filter(!is.na(GENDER), GENDER != "", GENDER != "UNKNOWN") %>%
    group_by(GENDER) %>%
    summarise(
      N = n(),
      N_ADRD = sum(true_label == 1),
      N_CTRL = sum(true_label == 0),
      .groups = "drop"
    )
  
  cat("Gender distribution:\n")
  print(gender_results)
  cat("\n")
  
  # Calculate metrics for each gender
  gender_metrics_list <- list()
  
  for (gender in unique(analysis_data$GENDER[!is.na(analysis_data$GENDER)])) {
    if (gender == "" || is.na(gender) || gender == "UNKNOWN") next
    
    subset_data <- analysis_data %>% filter(GENDER == gender)
    
    if (nrow(subset_data) < MIN_SUBGROUP_SIZE) {
      cat("  Skipping", gender, "(N =", nrow(subset_data), "<", MIN_SUBGROUP_SIZE, ")\n")
      next
    }
    
    metrics <- calculate_subgroup_metrics(
      subset_data$true_label,
      subset_data$predicted_prob,
      threshold = OPTIMAL_THRESHOLD,
      conf_level = CONFIDENCE_LEVEL
    )
    
    if (!is.null(metrics)) {
      metrics$subgroup <- "Gender"
      metrics$category <- as.character(gender)
      metrics$category_short <- simplify_category_name(gender)
      gender_metrics_list[[as.character(gender)]] <- metrics
      
      cat(gender, ":\n")
      cat("  N:", metrics$n, 
          sprintf("(ADRD: %d, CTRL: %d)", metrics$n_pos, metrics$n_neg), "\n")
      cat("  AUC:", sprintf("%.4f", metrics$auc), "\n")
      cat("  Accuracy:", sprintf("%.4f", metrics$accuracy), "\n")
      cat("  Sensitivity:", sprintf("%.4f", metrics$sensitivity), "\n")
      cat("  Specificity:", sprintf("%.4f", metrics$specificity), "\n")
      cat("  F1:", sprintf("%.4f", metrics$f1), "\n\n")
    }
  }
  
  # Compare genders
  if (length(gender_metrics_list) >= 2) {
    genders <- names(gender_metrics_list)
    auc_vals <- sapply(gender_metrics_list, function(x) x$auc)
    auc_diff <- abs(auc_vals[1] - auc_vals[2])

    sens_vals <- sapply(gender_metrics_list, function(x) x$sensitivity)
    sens_diff <- abs(sens_vals[1] - sens_vals[2])

    cat("Gender Performance Comparison:\n")
    cat("  AUC difference:", sprintf("%.4f", auc_diff))
    cat(ifelse(auc_diff > 0.05, " ‚ö† WARNING\n", " ‚úì OK\n"))
    cat("  Sensitivity difference:", sprintf("%.4f", sens_diff))
    cat(ifelse(sens_diff > 0.10, " ‚ö† WARNING\n", " ‚úì OK\n"))
    cat("\n")

    # STATISTICAL SIGNIFICANCE TEST (IMPROVEMENT 4)
    cat(strrep("-", 80) %+% "\n")
    cat("Statistical Significance Test\n")
    cat(strrep("-", 80) %+% "\n")

    chi_result <- perform_chi_squared_test(analysis_data, "GENDER", "true_label")

    cat("Test:", chi_result$method, "\n")
    if (!is.na(chi_result$statistic)) {
      cat("Statistic (œá¬≤):", sprintf("%.4f", chi_result$statistic), "\n")
      cat("Degrees of freedom:", chi_result$df, "\n")
    }
    cat("P-value:", sprintf("%.4f", chi_result$p_value), "\n")
    cat("Result:", chi_result$interpretation, "\n")

    if (chi_result$p_value < 0.05) {
      cat("\n‚ö†Ô∏è  FINDING: Gender significantly affects ADRD classification patterns\n")
      cat("   Clinical implication: Model may have gender-related bias\n")
    } else {
      cat("\n‚úì  Gender does not significantly affect classification patterns\n")
    }
    cat("\n")

    # Statistical significance testing
    if (RUN_STATISTICAL_TESTS && length(genders) == 2) {
      cat("Running statistical significance tests...\n")

      # Prepare data for statistical tests
      gender_a <- genders[1]
      gender_b <- genders[2]

      data_a <- analysis_data %>%
        filter(GENDER == gender_a) %>%
        select(label = true_label, pred = predicted_prob)

      data_b <- analysis_data %>%
        filter(GENDER == gender_b) %>%
        select(label = true_label, pred = predicted_prob)

      # Comprehensive comparison
      stat_result <- compare_groups_comprehensive(
        data_a, data_b,
        group_a_name = gender_a,
        group_b_name = gender_b,
        n_perm = N_PERMUTATIONS,
        n_boot = N_BOOTSTRAP
      )

      cat("\nStatistical Test Results:\n")
      cat("  Permutation test p-value:", sprintf("%.4f", stat_result$perm_p_value))
      if (stat_result$perm_p_value < FDR_ALPHA) {
        cat(" *** SIGNIFICANT\n")
      } else {
        cat(" (not significant)\n")
      }
      cat("  Cohen's d (effect size):", sprintf("%.3f", stat_result$cohens_d), "\n")
      cat("  Interpretation:",
          ifelse(abs(stat_result$cohens_d) >= 0.8, "Large effect",
          ifelse(abs(stat_result$cohens_d) >= 0.5, "Medium effect",
          ifelse(abs(stat_result$cohens_d) >= 0.2, "Small effect", "Negligible"))), "\n\n")

      # Store for later
      if (!exists("statistical_test_results")) {
        statistical_test_results <- list()
      }
      statistical_test_results$gender <- stat_result
    }
  }
}

# Race Analysis ===============================================================
if ("RACE" %in% available_demos) {
  cat(strrep("=", 80) %+% "\n")
  cat("Race-Stratified Analysis\n")
  cat(strrep("=", 80) %+% "\n\n")
  
  # Show distribution with full names
  race_results <- analysis_data %>%
    filter(!is.na(RACE), RACE != "", RACE != "UNKNOWN") %>%
    group_by(RACE) %>%
    summarise(
      N = n(),
      N_ADRD = sum(true_label == 1),
      N_CTRL = sum(true_label == 0),
      .groups = "drop"
    ) %>%
    arrange(desc(N))
  
  cat("Race distribution:\n")
  print(race_results, n = 20)
  cat("\n")
  
  # Calculate metrics for each race
  race_metrics_list <- list()
  
  for (race in race_results$RACE) {
    subset_data <- analysis_data %>% filter(RACE == race)
    
    if (nrow(subset_data) < MIN_SUBGROUP_SIZE) {
      cat("  Skipping '", race, "' (N =", nrow(subset_data), ")\n", sep = "")
      next
    }
    
    metrics <- calculate_subgroup_metrics(
      subset_data$true_label,
      subset_data$predicted_prob,
      threshold = OPTIMAL_THRESHOLD,
      conf_level = CONFIDENCE_LEVEL
    )
    
    if (!is.null(metrics)) {
      metrics$subgroup <- "Race"
      metrics$category <- as.character(race)
      metrics$category_short <- simplify_category_name(race)
      race_metrics_list[[as.character(race)]] <- metrics
      
      cat("'", race, "' (", simplify_category_name(race), "):\n", sep = "")
      cat("  N:", metrics$n,
          sprintf("(ADRD: %d, CTRL: %d)", metrics$n_pos, metrics$n_neg), "\n")
      cat("  AUC:", sprintf("%.4f", metrics$auc), "\n")
      cat("  Accuracy:", sprintf("%.4f", metrics$accuracy), "\n")
      cat("  Sensitivity:", sprintf("%.4f", metrics$sensitivity), "\n")
      cat("  Specificity:", sprintf("%.4f", metrics$specificity), "\n")
      cat("  F1:", sprintf("%.4f", metrics$f1), "\n\n")
    }
  }
  
  # Analyze racial disparities
  if (length(race_metrics_list) >= 2) {
    race_aucs <- sapply(race_metrics_list, function(x) x$auc)
    race_sens <- sapply(race_metrics_list, function(x) x$sensitivity)
    
    auc_range <- max(race_aucs, na.rm = TRUE) - min(race_aucs, na.rm = TRUE)
    sens_range <- max(race_sens, na.rm = TRUE) - min(race_sens, na.rm = TRUE)
    
    cat("Race Performance Variability:\n")
    cat("  Number of racial groups:", length(race_metrics_list), "\n")
    cat("  AUC range:", sprintf("%.4f", auc_range))
    cat(ifelse(auc_range > 0.10, " ‚ö† WARNING: Large variability\n", " ‚úì OK\n"))
    cat("  Sensitivity range:", sprintf("%.4f", sens_range))
    cat(ifelse(sens_range > 0.15, " ‚ö† WARNING: Large variability\n", " ‚úì OK\n"))
    cat("\n")

    # STATISTICAL SIGNIFICANCE TEST (IMPROVEMENT 4)
    cat(strrep("-", 80) %+% "\n")
    cat("Statistical Significance Test\n")
    cat(strrep("-", 80) %+% "\n")

    chi_result <- perform_chi_squared_test(analysis_data, "RACE", "true_label")

    cat("Test:", chi_result$method, "\n")
    if (!is.na(chi_result$statistic)) {
      cat("Statistic (œá¬≤):", sprintf("%.4f", chi_result$statistic), "\n")
      cat("Degrees of freedom:", chi_result$df, "\n")
    }
    cat("P-value:", sprintf("%.4f", chi_result$p_value), "\n")
    cat("Result:", chi_result$interpretation, "\n")

    if (chi_result$p_value < 0.05) {
      cat("\n‚ö†Ô∏è  FINDING: Race significantly affects ADRD classification patterns\n")
      cat("   Clinical implication: Model performance varies by racial group\n")
    } else {
      cat("\n‚úì  Race does not significantly affect classification patterns\n")
    }
    cat("\n")
  }
}

# Ethnicity Analysis ==========================================================
if ("HISPANIC" %in% available_demos) {
  cat(strrep("=", 80) %+% "\n")
  cat("Ethnicity-Stratified Analysis\n")
  cat(strrep("=", 80) %+% "\n\n")
  
  # Show distribution with full names
  ethnicity_results <- analysis_data %>%
    filter(!is.na(HISPANIC), HISPANIC != "", HISPANIC != "UNKNOWN") %>%
    group_by(HISPANIC) %>%
    summarise(
      N = n(),
      N_ADRD = sum(true_label == 1),
      N_CTRL = sum(true_label == 0),
      .groups = "drop"
    ) %>%
    arrange(desc(N))
  
  cat("Ethnicity distribution:\n")
  print(ethnicity_results)
  cat("\n")
  
  # Calculate metrics for each ethnicity
  ethnicity_metrics_list <- list()
  
  for (hisp in ethnicity_results$HISPANIC) {
    subset_data <- analysis_data %>% filter(HISPANIC == hisp)
    
    if (nrow(subset_data) < MIN_SUBGROUP_SIZE) {
      cat("  Skipping '", hisp, "' (N =", nrow(subset_data), ")\n", sep = "")
      next
    }
    
    metrics <- calculate_subgroup_metrics(
      subset_data$true_label,
      subset_data$predicted_prob,
      threshold = OPTIMAL_THRESHOLD,
      conf_level = CONFIDENCE_LEVEL
    )
    
    if (!is.null(metrics)) {
      metrics$subgroup <- "Ethnicity"
      metrics$category <- as.character(hisp)
      metrics$category_short <- simplify_category_name(hisp)
      ethnicity_metrics_list[[as.character(hisp)]] <- metrics
      
      cat("'", hisp, "' (", simplify_category_name(hisp), "):\n", sep = "")
      cat("  N:", metrics$n,
          sprintf("(ADRD: %d, CTRL: %d)", metrics$n_pos, metrics$n_neg), "\n")
      cat("  AUC:", sprintf("%.4f", metrics$auc), "\n")
      cat("  Accuracy:", sprintf("%.4f", metrics$accuracy), "\n")
      cat("  Sensitivity:", sprintf("%.4f", metrics$sensitivity), "\n")
      cat("  Specificity:", sprintf("%.4f", metrics$specificity), "\n")
      cat("  F1:", sprintf("%.4f", metrics$f1), "\n\n")
    }
  }
  
  # Compare Hispanic vs Non-Hispanic if both exist
  if (length(ethnicity_metrics_list) >= 2) {
    hisp_aucs <- sapply(ethnicity_metrics_list, function(x) x$auc)
    auc_diff <- max(hisp_aucs, na.rm = TRUE) - min(hisp_aucs, na.rm = TRUE)
    
    cat("Ethnicity Performance Comparison:\n")
    cat("  AUC difference:", sprintf("%.4f", auc_diff))
    cat(ifelse(auc_diff > 0.05, " ‚ö† WARNING\n", " ‚úì OK\n"))
    cat("\n")

    # STATISTICAL SIGNIFICANCE TEST (IMPROVEMENT 4)
    cat(strrep("-", 80) %+% "\n")
    cat("Statistical Significance Test\n")
    cat(strrep("-", 80) %+% "\n")

    chi_result <- perform_chi_squared_test(analysis_data, "HISPANIC", "true_label")

    cat("Test:", chi_result$method, "\n")
    if (!is.na(chi_result$statistic)) {
      cat("Statistic (œá¬≤):", sprintf("%.4f", chi_result$statistic), "\n")
      cat("Degrees of freedom:", chi_result$df, "\n")
    }
    cat("P-value:", sprintf("%.4f", chi_result$p_value), "\n")
    cat("Result:", chi_result$interpretation, "\n")

    if (chi_result$p_value < 0.05) {
      cat("\n‚ö†Ô∏è  FINDING: Ethnicity significantly affects ADRD classification patterns\n")
      cat("   Clinical implication: Model performance differs by ethnicity\n")
    } else {
      cat("\n‚úì  Ethnicity does not significantly affect classification patterns\n")
    }
    cat("\n")
  }
}

# ==============================================================================
# Insurance Analysis (SDOH)
# ==============================================================================
if ("INSURANCE" %in% sdoh_variables) {
  cat(strrep("=", 80) %+% "\n")
  cat("Insurance-Stratified Analysis (Social Determinant)\n")
  cat(strrep("=", 80) %+% "\n\n")

  insurance_dist <- analysis_data %>%
    filter(!is.na(INSURANCE)) %>%
    group_by(INSURANCE) %>%
    summarise(N = n(), N_ADRD = sum(true_label == 1), N_CTRL = sum(true_label == 0), .groups = "drop") %>%
    arrange(desc(N))

  cat("Insurance type distribution:\n")
  print(insurance_dist)
  cat("\n")

  insurance_metrics_list <- list()

  for (ins_type in insurance_dist$INSURANCE) {
    subset_data <- analysis_data %>% filter(INSURANCE == ins_type)

    if (nrow(subset_data) < MIN_SUBGROUP_SIZE) {
      cat("  Skipping", ins_type, "(N =", nrow(subset_data), "< min)\n")
      next
    }

    metrics <- calculate_subgroup_metrics(subset_data$true_label, subset_data$predicted_prob,
                                          threshold = OPTIMAL_THRESHOLD, conf_level = CONFIDENCE_LEVEL)

    if (!is.null(metrics)) {
      metrics$subgroup <- "Insurance"
      metrics$category <- as.character(ins_type)
      metrics$category_short <- as.character(ins_type)
      insurance_metrics_list[[as.character(ins_type)]] <- metrics

      cat(ins_type, ":\n")
      cat("  N:", metrics$n, sprintf("(ADRD:%d, CTRL:%d)", metrics$n_pos, metrics$n_neg), "\n")
      cat("  AUC:", sprintf("%.4f [%.4f-%.4f]", metrics$auc, metrics$auc_ci_lower, metrics$auc_ci_upper), "\n")
      cat("  Sensitivity:", sprintf("%.4f", metrics$sensitivity), "Specificity:", sprintf("%.4f", metrics$specificity), "\n")
      cat("  F1:", sprintf("%.4f", metrics$f1), "\n\n")
    }
  }

  if (length(insurance_metrics_list) >= 2) {
    ins_aucs <- sapply(insurance_metrics_list, function(x) x$auc)
    ins_sens <- sapply(insurance_metrics_list, function(x) x$sensitivity)
    auc_range <- max(ins_aucs, na.rm=TRUE) - min(ins_aucs, na.rm=TRUE)
    sens_range <- max(ins_sens, na.rm=TRUE) - min(ins_sens, na.rm=TRUE)

    cat("Insurance Performance Comparison:\n")
    cat("  Insurance types analyzed:", length(insurance_metrics_list), "\n")
    cat("  AUC range:", sprintf("%.4f", auc_range))
    cat(ifelse(auc_range > 0.10, " ‚ö†Ô∏è  WARNING: Large disparity\n", " ‚úì OK\n"))
    cat("  Sensitivity range:", sprintf("%.4f", sens_range))
    cat(ifelse(sens_range > 0.15, " ‚ö†Ô∏è  WARNING: Large disparity\n", " ‚úì OK\n"))
    cat("\n")

    cat(strrep("-", 80) %+% "\n")
    cat("Statistical Significance Test\n")
    cat(strrep("-", 80) %+% "\n")

    chi_result <- perform_chi_squared_test(analysis_data, "INSURANCE", "true_label")
    cat("Test:", chi_result$method, "\n")
    if (!is.na(chi_result$statistic)) {
      cat("Statistic (œá¬≤):", sprintf("%.4f", chi_result$statistic), "\n")
      cat("Degrees of freedom:", chi_result$df, "\n")
    }
    cat("P-value:", sprintf("%.4f", chi_result$p_value), "\n")
    cat("Result:", chi_result$interpretation, "\n")

    if (chi_result$p_value < 0.05) {
      cat("\n‚ö†Ô∏è  FINDING: Insurance type significantly affects ADRD classification\n")
      cat("   Socioeconomic implication: Model performance varies by insurance status\n")
    } else {
      cat("\n‚úì  Insurance does not significantly affect classification patterns\n")
    }
    cat("\n")
  }
}

# ==============================================================================
# Education Analysis (SDOH)
# ==============================================================================
if ("EDUCATION" %in% sdoh_variables) {
  cat(strrep("=", 80) %+% "\n")
  cat("Education-Stratified Analysis (Social Determinant)\n")
  cat(strrep("=", 80) %+% "\n\n")

  education_dist <- analysis_data %>%
    filter(!is.na(EDUCATION)) %>%
    group_by(EDUCATION) %>%
    summarise(N = n(), N_ADRD = sum(true_label == 1), N_CTRL = sum(true_label == 0), .groups = "drop") %>%
    arrange(desc(N))

  cat("Education level distribution:\n")
  print(education_dist)
  cat("\n")

  education_metrics_list <- list()

  for (edu_level in education_dist$EDUCATION) {
    subset_data <- analysis_data %>% filter(EDUCATION == edu_level)

    if (nrow(subset_data) < MIN_SUBGROUP_SIZE) {
      cat("  Skipping", edu_level, "(N =", nrow(subset_data), "< min)\n")
      next
    }

    metrics <- calculate_subgroup_metrics(subset_data$true_label, subset_data$predicted_prob,
                                          threshold = OPTIMAL_THRESHOLD, conf_level = CONFIDENCE_LEVEL)

    if (!is.null(metrics)) {
      metrics$subgroup <- "Education"
      metrics$category <- as.character(edu_level)
      metrics$category_short <- as.character(edu_level)
      education_metrics_list[[as.character(edu_level)]] <- metrics

      cat(edu_level, ":\n")
      cat("  N:", metrics$n, sprintf("(ADRD:%d, CTRL:%d)", metrics$n_pos, metrics$n_neg), "\n")
      cat("  AUC:", sprintf("%.4f [%.4f-%.4f]", metrics$auc, metrics$auc_ci_lower, metrics$auc_ci_upper), "\n")
      cat("  Sensitivity:", sprintf("%.4f", metrics$sensitivity), "Specificity:", sprintf("%.4f", metrics$specificity), "\n")
      cat("  F1:", sprintf("%.4f", metrics$f1), "\n\n")
    }
  }

  if (length(education_metrics_list) >= 2) {
    edu_aucs <- sapply(education_metrics_list, function(x) x$auc)
    edu_sens <- sapply(education_metrics_list, function(x) x$sensitivity)
    auc_range <- max(edu_aucs, na.rm=TRUE) - min(edu_aucs, na.rm=TRUE)
    sens_range <- max(edu_sens, na.rm=TRUE) - min(edu_sens, na.rm=TRUE)

    cat("Education Performance Comparison:\n")
    cat("  Education levels analyzed:", length(education_metrics_list), "\n")
    cat("  AUC range:", sprintf("%.4f", auc_range))
    cat(ifelse(auc_range > 0.10, " ‚ö†Ô∏è  WARNING: Large disparity\n", " ‚úì OK\n"))
    cat("  Sensitivity range:", sprintf("%.4f", sens_range))
    cat(ifelse(sens_range > 0.15, " ‚ö†Ô∏è  WARNING: Large disparity\n", " ‚úì OK\n"))
    cat("\n")

    cat(strrep("-", 80) %+% "\n")
    cat("Statistical Significance Test\n")
    cat(strrep("-", 80) %+% "\n")

    chi_result <- perform_chi_squared_test(analysis_data, "EDUCATION", "true_label")
    cat("Test:", chi_result$method, "\n")
    if (!is.na(chi_result$statistic)) {
      cat("Statistic (œá¬≤):", sprintf("%.4f", chi_result$statistic), "\n")
      cat("Degrees of freedom:", chi_result$df, "\n")
    }
    cat("P-value:", sprintf("%.4f", chi_result$p_value), "\n")
    cat("Result:", chi_result$interpretation, "\n")

    if (chi_result$p_value < 0.05) {
      cat("\n‚ö†Ô∏è  FINDING: Education level significantly affects ADRD classification\n")
      cat("   Socioeconomic implication: Model performance varies by education\n")
    } else {
      cat("\n‚úì  Education does not significantly affect classification patterns\n")
    }
    cat("\n")
  }
}

# ==============================================================================
# Financial Class Analysis (SDOH)
# ==============================================================================
if ("FINANCIAL_CLASS" %in% sdoh_variables) {
  cat(strrep("=", 80) %+% "\n")
  cat("Financial Class-Stratified Analysis (Social Determinant)\n")
  cat(strrep("=", 80) %+% "\n\n")

  financial_dist <- analysis_data %>%
    filter(!is.na(FINANCIAL_CLASS)) %>%
    group_by(FINANCIAL_CLASS) %>%
    summarise(N = n(), N_ADRD = sum(true_label == 1), N_CTRL = sum(true_label == 0), .groups = "drop") %>%
    arrange(desc(N))

  cat("Financial class distribution:\n")
  print(financial_dist)
  cat("\n")

  financial_metrics_list <- list()

  for (fin_class in financial_dist$FINANCIAL_CLASS) {
    subset_data <- analysis_data %>% filter(FINANCIAL_CLASS == fin_class)

    if (nrow(subset_data) < MIN_SUBGROUP_SIZE) {
      cat("  Skipping", fin_class, "(N =", nrow(subset_data), "< min)\n")
      next
    }

    metrics <- calculate_subgroup_metrics(subset_data$true_label, subset_data$predicted_prob,
                                          threshold = OPTIMAL_THRESHOLD, conf_level = CONFIDENCE_LEVEL)

    if (!is.null(metrics)) {
      metrics$subgroup <- "Financial Class"
      metrics$category <- as.character(fin_class)
      metrics$category_short <- as.character(fin_class)
      financial_metrics_list[[as.character(fin_class)]] <- metrics

      cat(fin_class, ":\n")
      cat("  N:", metrics$n, sprintf("(ADRD:%d, CTRL:%d)", metrics$n_pos, metrics$n_neg), "\n")
      cat("  AUC:", sprintf("%.4f [%.4f-%.4f]", metrics$auc, metrics$auc_ci_lower, metrics$auc_ci_upper), "\n")
      cat("  Sensitivity:", sprintf("%.4f", metrics$sensitivity), "Specificity:", sprintf("%.4f", metrics$specificity), "\n")
      cat("  F1:", sprintf("%.4f", metrics$f1), "\n\n")
    }
  }

  if (length(financial_metrics_list) >= 2) {
    fin_aucs <- sapply(financial_metrics_list, function(x) x$auc)
    fin_sens <- sapply(financial_metrics_list, function(x) x$sensitivity)
    auc_range <- max(fin_aucs, na.rm=TRUE) - min(fin_aucs, na.rm=TRUE)
    sens_range <- max(fin_sens, na.rm=TRUE) - min(fin_sens, na.rm=TRUE)

    cat("Financial Class Performance Comparison:\n")
    cat("  Financial classes analyzed:", length(financial_metrics_list), "\n")
    cat("  AUC range:", sprintf("%.4f", auc_range))
    cat(ifelse(auc_range > 0.10, " ‚ö†Ô∏è  WARNING: Large disparity\n", " ‚úì OK\n"))
    cat("  Sensitivity range:", sprintf("%.4f", sens_range))
    cat(ifelse(sens_range > 0.15, " ‚ö†Ô∏è  WARNING: Large disparity\n", " ‚úì OK\n"))
    cat("\n")

    cat(strrep("-", 80) %+% "\n")
    cat("Statistical Significance Test\n")
    cat(strrep("-", 80) %+% "\n")

    chi_result <- perform_chi_squared_test(analysis_data, "FINANCIAL_CLASS", "true_label")
    cat("Test:", chi_result$method, "\n")
    if (!is.na(chi_result$statistic)) {
      cat("Statistic (œá¬≤):", sprintf("%.4f", chi_result$statistic), "\n")
      cat("Degrees of freedom:", chi_result$df, "\n")
    }
    cat("P-value:", sprintf("%.4f", chi_result$p_value), "\n")
    cat("Result:", chi_result$interpretation, "\n")

    if (chi_result$p_value < 0.05) {
      cat("\n‚ö†Ô∏è  FINDING: Financial class significantly affects ADRD classification\n")
      cat("   Socioeconomic implication: Model performance varies by financial status\n")
    } else {
      cat("\n‚úì  Financial class does not significantly affect classification patterns\n")
    }
    cat("\n")
  }
}

# ==============================================================================
# Intersectional Analysis: Gender √ó Race
# ==============================================================================
if ("GENDER" %in% available_demos && "RACE" %in% available_demos) {
  cat(strrep("=", 80) %+% "\n")
  cat("Intersectional Analysis: Gender √ó Race Combinations\n")
  cat(strrep("=", 80) %+% "\n\n")

  intersect_data <- analysis_data %>%
    filter(!is.na(GENDER), !is.na(RACE)) %>%
    mutate(
      intersection = paste(GENDER, "√ó", RACE),
      intersection_short = paste(GENDER, simplify_category_name(RACE), sep=" √ó ")
    )

  intersect_dist <- intersect_data %>%
    group_by(intersection, intersection_short, GENDER, RACE) %>%
    summarise(N = n(), N_ADRD = sum(true_label == 1), N_CTRL = sum(true_label == 0), .groups = "drop") %>%
    arrange(desc(N))

  cat("Intersectional groups with N ‚â• 30:\n")
  print(intersect_dist %>% filter(N >= 30))
  cat("\n")

  intersect_metrics_list <- list()

  for (i in 1:nrow(intersect_dist)) {
    if (intersect_dist$N[i] < 30) next

    group_name <- intersect_dist$intersection[i]
    subset_data <- intersect_data %>% filter(intersection == group_name)

    metrics <- calculate_subgroup_metrics(subset_data$true_label, subset_data$predicted_prob,
                                          threshold = OPTIMAL_THRESHOLD, conf_level = CONFIDENCE_LEVEL)

    if (!is.null(metrics)) {
      metrics$subgroup <- "Gender √ó Race"
      metrics$category <- group_name
      metrics$category_short <- intersect_dist$intersection_short[i]
      metrics$gender <- intersect_dist$GENDER[i]
      metrics$race <- intersect_dist$RACE[i]
      intersect_metrics_list[[group_name]] <- metrics

      cat(group_name, ":\n")
      cat("  N:", metrics$n, "| AUC:", sprintf("%.4f", metrics$auc),
          "| Sens:", sprintf("%.4f", metrics$sensitivity),
          "| Spec:", sprintf("%.4f", metrics$specificity), "\n")
    }
  }

  if (length(intersect_metrics_list) >= 4) {
    int_aucs <- sapply(intersect_metrics_list, function(x) x$auc)
    auc_range <- max(int_aucs, na.rm=TRUE) - min(int_aucs, na.rm=TRUE)

    cat("\nIntersectional Performance Range:\n")
    cat("  AUC range across intersections:", sprintf("%.4f", auc_range))
    cat(ifelse(auc_range > 0.10, " ‚ö†Ô∏è  WARNING: Compound disparities exist\n", " ‚úì OK\n"))

    best_group <- names(int_aucs)[which.max(int_aucs)]
    worst_group <- names(int_aucs)[which.min(int_aucs)]

    cat("\n  Best performing:", best_group, sprintf("(AUC=%.4f)", max(int_aucs)), "\n")
    cat("  Worst performing:", worst_group, sprintf("(AUC=%.4f)", min(int_aucs)), "\n")
    cat("  Performance gap:", sprintf("%.4f", max(int_aucs) - min(int_aucs)), "\n\n")

    if (auc_range > 0.10) {
      cat("‚ö†Ô∏è  FINDING: Compound disparities detected across intersectional groups\n")
      cat("   Recommendation: Targeted model recalibration for underperforming groups\n\n")
    }
  }
}

# Compile All Results =========================================================
cat(strrep("=", 80) %+% "\n")
cat("Compiling Results\n")
cat(strrep("=", 80) %+% "\n\n")

all_subgroup_metrics <- bind_rows(
  if (exists("gender_metrics_list") && length(gender_metrics_list) > 0) {
    bind_rows(lapply(gender_metrics_list, as.data.frame))
  },
  if (exists("race_metrics_list") && length(race_metrics_list) > 0) {
    bind_rows(lapply(race_metrics_list, as.data.frame))
  },
  if (exists("ethnicity_metrics_list") && length(ethnicity_metrics_list) > 0) {
    bind_rows(lapply(ethnicity_metrics_list, as.data.frame))
  },
  if (exists("insurance_metrics_list") && length(insurance_metrics_list) > 0) {
    bind_rows(lapply(insurance_metrics_list, as.data.frame))
  },
  if (exists("education_metrics_list") && length(education_metrics_list) > 0) {
    bind_rows(lapply(education_metrics_list, as.data.frame))
  },
  if (exists("financial_metrics_list") && length(financial_metrics_list) > 0) {
    bind_rows(lapply(financial_metrics_list, as.data.frame))
  },
  if (exists("intersect_metrics_list") && length(intersect_metrics_list) > 0) {
    bind_rows(lapply(intersect_metrics_list, as.data.frame))
  }
)

if (nrow(all_subgroup_metrics) > 0) {
  # Add overall metrics
  overall_df <- as.data.frame(overall_metrics)
  overall_df$subgroup <- "Overall"
  overall_df$category <- "All"
  overall_df$category_short <- "All"
  
  all_subgroup_metrics <- bind_rows(overall_df, all_subgroup_metrics)
  
  # Add simplified category names if not already present
  if (!"category_short" %in% names(all_subgroup_metrics)) {
    all_subgroup_metrics <- all_subgroup_metrics %>%
      mutate(category_short = sapply(category, simplify_category_name))
  }
  
  # Save results
  metrics_file <- file.path(DEMO_RESULTS_DIR, "subgroup_performance.csv")
  write_csv(all_subgroup_metrics, metrics_file)
  cat("Subgroup metrics saved:", metrics_file, "\n")
  
  write_xlsx(all_subgroup_metrics,
             file.path(DEMO_RESULTS_DIR, "subgroup_performance.xlsx"))
  cat("Excel format saved\n")
  
  saveRDS(all_subgroup_metrics,
          file.path(DEMO_RESULTS_DIR, "subgroup_performance.rds"))
  cat("RDS format saved\n\n")
} else {
  cat("WARNING: No subgroup metrics calculated\n\n")
}

# Create Visualizations =======================================================
cat(strrep("=", 80) %+% "\n")
cat("Creating Visualizations\n")
cat(strrep("=", 80) %+% "\n\n")

if (nrow(all_subgroup_metrics) > 1) {
  
  # Prepare data for plotting - ENHANCED with factor categorization
  plot_data <- all_subgroup_metrics %>%
    filter(subgroup != "Overall") %>%
    mutate(
      display_name = ifelse(!is.na(category_short), category_short, category),
      display_name = wrap_text(display_name, width = 15),
      factor_type = case_when(
        subgroup %in% c("Gender", "Race", "Ethnicity", "Age") ~ "Demographic",
        subgroup %in% c("Insurance", "Education", "Financial Class") ~ "SDOH",
        grepl("√ó", subgroup) ~ "Intersectional",
        TRUE ~ "Other"
      ),
      low_performance = auc < (overall_metrics$auc - 0.05)
    )

  # 1. ENHANCED AUC Comparison Plot with factor types
  cat("Creating enhanced AUC comparison plot...\n")

  auc_plot <- ggplot(plot_data,
                     aes(x = reorder(display_name, auc), y = auc,
                         fill = factor_type, alpha = low_performance)) +
    geom_bar(stat = "identity", width = 0.7) +
    geom_errorbar(aes(ymin = auc_ci_lower, ymax = auc_ci_upper),
                  width = 0.2, linewidth = 0.5) +
    geom_text(aes(label = sprintf("n=%d", n)),
              vjust = -2.5, size = 2.5, color = "black") +
    geom_text(aes(label = sprintf("%.3f", auc)),
              vjust = -0.8, size = 3, fontface = "bold") +
    geom_hline(yintercept = overall_metrics$auc,
               linetype = "dashed", color = "red", linewidth = 0.8) +
    scale_fill_manual(
      values = c("Demographic" = "#8dd3c7", "SDOH" = "#fb8072",
                 "Intersectional" = "#bebada"),
      name = "Factor Type"
    ) +
    scale_alpha_manual(values = c("TRUE" = 0.6, "FALSE" = 0.9), guide = "none") +
    facet_wrap(~factor_type, scales = "free_x", ncol = 1) +
    labs(
      title = "Model Performance Across Demographic, SDOH, and Intersectional Subgroups",
      subtitle = sprintf("Dashed line = Overall AUC (%.3f) | Error bars = 95%% CI | Faded bars = AUC < baseline-0.05",
                        overall_metrics$auc),
      x = "Subgroup",
      y = "AUC (Area Under ROC Curve)"
    ) +
    theme_classic() +
    theme(
      plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
      plot.subtitle = element_text(size = 10, hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 9),
      axis.text.y = element_text(size = 10),
      axis.title = element_text(size = 12, face = "bold"),
      legend.position = "bottom",
      strip.text = element_text(size = 11, face = "bold"),
      strip.background = element_rect(fill = "lightgray", color = "black")
    ) +
    coord_cartesian(ylim = c(0.70, 1.0))

  ggsave(file.path(DEMO_FIGURES_DIR, "auc_by_subgroup_enhanced.png"),
         plot = auc_plot, width = 14, height = 10, dpi = 300)
  cat("  Enhanced AUC comparison saved\n")
  
  # 2. Sensitivity vs Specificity
  cat("Creating sensitivity-specificity plot...\n")
  
  sens_spec_plot <- ggplot(plot_data,
                           aes(x = specificity, y = sensitivity, 
                               color = subgroup, shape = subgroup)) +
    geom_point(size = 4, alpha = 0.8) +
    geom_text(aes(label = display_name), vjust = -1.2, size = 3, hjust = 0.5) +
    geom_hline(yintercept = overall_metrics$sensitivity, 
               linetype = "dashed", alpha = 0.5) +
    geom_vline(xintercept = overall_metrics$specificity, 
               linetype = "dashed", alpha = 0.5) +
    scale_color_brewer(palette = "Set1") +
    labs(title = "Sensitivity vs Specificity by Subgroup",
         subtitle = "Dashed lines = Overall performance",
         x = "Specificity", y = "Sensitivity",
         color = "Dimension", shape = "Dimension") +
    theme_classic() +
    theme(
      plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
      plot.subtitle = element_text(size = 11, hjust = 0.5),
      axis.text = element_text(size = 10),
      axis.title = element_text(size = 12, face = "bold"),
      legend.position = "bottom"
    ) +
    coord_cartesian(xlim = c(0.7, 1.0), ylim = c(0.7, 1.0))
  
  ggsave(file.path(DEMO_FIGURES_DIR, "sensitivity_specificity.png"),
         plot = sens_spec_plot, width = 10, height = 10, dpi = 300)
  cat("  Sensitivity-specificity plot saved\n")
  
  # 3. Multiple metrics comparison
  cat("Creating comprehensive metrics comparison...\n")
  
  metrics_comparison <- plot_data %>%
    select(subgroup, display_name, auc, accuracy, sensitivity, specificity, f1) %>%
    pivot_longer(cols = c(auc, accuracy, sensitivity, specificity, f1),
                 names_to = "metric", values_to = "value") %>%
    mutate(metric = factor(metric,
                          levels = c("auc","accuracy","sensitivity","specificity","f1"),
                          labels = c("AUC","Accuracy","Sensitivity","Specificity","F1 Score")))
  
  metrics_plot <- ggplot(metrics_comparison,
                         aes(x = display_name, y = value, fill = metric)) +
    geom_bar(stat = "identity", position = "dodge", alpha = 0.8, width = 0.8) +
    facet_wrap(~subgroup, scales = "free_x", ncol = 2) +
    scale_fill_brewer(palette = "Set2") +
    labs(title = "Performance Metrics Across Demographic Subgroups",
         x = "Subgroup", y = "Metric Value", fill = "Metric") +
    theme_classic() +
    theme(
      plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
      axis.text.y = element_text(size = 9),
      axis.title = element_text(size = 11, face = "bold"),
      legend.position = "bottom",
      strip.text = element_text(size = 11, face = "bold"),
      strip.background = element_rect(fill = "lightgray")
    ) +
    coord_cartesian(ylim = c(0.6, 1.0))
  
  ggsave(file.path(DEMO_FIGURES_DIR, "metrics_comparison.png"),
         plot = metrics_plot, width = 14, height = 10, dpi = 300)
  cat("  Metrics comparison saved\n\n")

  # 4. Intersectional Performance Heatmap
  if (exists("intersect_metrics_list") && length(intersect_metrics_list) >= 4) {
    cat("Creating intersectional heatmap...\n")

    heatmap_data <- bind_rows(lapply(intersect_metrics_list, as.data.frame)) %>%
      mutate(
        Gender_short = ifelse("gender" %in% names(.), gender, NA_character_),
        Race_short = ifelse("race" %in% names(.), simplify_category_name(race), NA_character_)
      )

    if ("Gender_short" %in% names(heatmap_data) && "Race_short" %in% names(heatmap_data)) {
      heatmap_plot <- ggplot(heatmap_data, aes(x = Race_short, y = Gender_short, fill = auc)) +
        geom_tile(color = "white", linewidth = 1) +
        geom_text(aes(label = sprintf("%.3f\nn=%d", auc, n)),
                  color = "white", size = 4, fontface = "bold") +
        scale_fill_gradient2(
          low = "#d73027",
          mid = "#fee08b",
          high = "#1a9850",
          midpoint = overall_metrics$auc,
          limits = c(0.70, 1.0),
          name = "AUC"
        ) +
        labs(
          title = "Intersectional Performance: Gender √ó Race",
          subtitle = sprintf("Color scale centered at overall AUC (%.3f) | N ‚â• 30 samples required",
                            overall_metrics$auc),
          x = "Race Category",
          y = "Gender"
        ) +
        theme_minimal() +
        theme(
          plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
          plot.subtitle = element_text(size = 11, hjust = 0.5),
          axis.text.x = element_text(angle = 45, hjust = 1, size = 11),
          axis.text.y = element_text(size = 11),
          axis.title = element_text(size = 12, face = "bold"),
          legend.position = "right",
          panel.grid = element_blank()
        )

      ggsave(file.path(DEMO_FIGURES_DIR, "intersectional_heatmap.png"),
             plot = heatmap_plot, width = 12, height = 6, dpi = 300)
      cat("  Intersectional heatmap saved\n\n")
    }
  }
}

# Create Final Report =========================================================
cat(strrep("=", 80) %+% "\n")
cat("Creating Comprehensive Report\n")
cat(strrep("=", 80) %+% "\n\n")

report_file <- file.path(DEMO_RESULTS_DIR, "demographic_analysis_report.txt")
sink(report_file)

cat("ADRD ePhenotyping - Demographic Performance Analysis Report\n")
cat("Aim 1: Evaluate Model Performance Across Demographic Groups\n")
cat(strrep("=", 80), "\n\n")

cat("Date:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n")
cat("Classification Threshold:", OPTIMAL_THRESHOLD, "\n\n")

cat("Overall Test Set Performance:\n")
cat(strrep("-", 40), "\n")
cat("Total samples:", overall_metrics$n, "\n")
cat("ADRD cases:", overall_metrics$n_pos,
    sprintf("(%.1f%%)", overall_metrics$n_pos / overall_metrics$n * 100), "\n")
cat("Control cases:", overall_metrics$n_neg,
    sprintf("(%.1f%%)", overall_metrics$n_neg / overall_metrics$n * 100), "\n")
cat("AUC:", sprintf("%.4f", overall_metrics$auc))
if (!is.na(overall_metrics$auc_ci_lower)) {
  cat(sprintf(" (95%% CI: %.4f-%.4f)", overall_metrics$auc_ci_lower,
              overall_metrics$auc_ci_upper))
}
cat("\n")
cat("Accuracy:", sprintf("%.4f", overall_metrics$accuracy), "\n")
cat("Sensitivity:", sprintf("%.4f", overall_metrics$sensitivity), "\n")
cat("Specificity:", sprintf("%.4f", overall_metrics$specificity), "\n")
cat("F1 Score:", sprintf("%.4f", overall_metrics$f1), "\n\n")

cat("Demographic Variables Analyzed:\n")
cat(strrep("-", 40), "\n")
cat(paste(available_demos, collapse = ", "), "\n\n")

if (nrow(all_subgroup_metrics) > 0) {
  cat("Performance by Demographic Subgroups:\n")
  cat(strrep("-", 40), "\n")
  print(all_subgroup_metrics %>%
          select(subgroup, category, n, n_pos, n_neg, auc, accuracy, 
                 sensitivity, specificity, f1) %>%
          arrange(subgroup, desc(n)))
  cat("\n")
}

cat("Key Findings:\n")
cat(strrep("-", 40), "\n")

# Identify disparities
if (exists("race_metrics_list") && length(race_metrics_list) >= 2) {
  race_aucs <- sapply(race_metrics_list, function(x) x$auc)
  auc_range <- max(race_aucs, na.rm = TRUE) - min(race_aucs, na.rm = TRUE)
  if (auc_range > 0.10) {
    cat("- ‚ö† WARNING: Large AUC variability across racial groups (", 
        sprintf("%.3f", auc_range), ")\n", sep = "")
  } else {
    cat("- ‚úì Racial fairness: AUC variability within acceptable range (", 
        sprintf("%.3f", auc_range), ")\n", sep = "")
  }
}

if (exists("gender_metrics_list") && length(gender_metrics_list) >= 2) {
  genders <- names(gender_metrics_list)
  sens_diff <- abs(gender_metrics_list[[genders[1]]]$sensitivity -
                   gender_metrics_list[[genders[2]]]$sensitivity)
  if (sens_diff > 0.10) {
    cat("- ‚ö† WARNING: Gender sensitivity difference >10% (",
        sprintf("%.3f", sens_diff), ")\n", sep = "")
  } else {
    cat("- ‚úì Gender fairness: Sensitivity difference within acceptable range (",
        sprintf("%.3f", sens_diff), ")\n", sep = "")
  }
}

# SDOH FINDINGS
if (length(sdoh_variables) > 0) {
  cat("\nSOCIAL DETERMINANTS OF HEALTH ANALYSIS\n")
  cat(strrep("-", 40), "\n")
  cat("Variables analyzed:", paste(sdoh_variables, collapse = ", "), "\n\n")

  for (sdoh_var in sdoh_variables) {
    list_name <- paste0(tolower(gsub(" ", "_", sdoh_var)), "_metrics_list")
    if (exists(list_name)) {
      metrics_list <- get(list_name)
      if (length(metrics_list) >= 2) {
        aucs <- sapply(metrics_list, function(x) x$auc)
        cat(sdoh_var, ":\n")
        cat("  Categories:", length(metrics_list), "\n")
        cat("  AUC range:", sprintf("%.4f", max(aucs, na.rm=TRUE) - min(aucs, na.rm=TRUE)))
        if ((max(aucs, na.rm=TRUE) - min(aucs, na.rm=TRUE)) > 0.10) {
          cat(" ‚ö†Ô∏è  WARNING\n")
        } else {
          cat(" ‚úì OK\n")
        }
        cat("  Best:", names(which.max(aucs)), sprintf("(%.4f)", max(aucs)), "\n")
        cat("  Worst:", names(which.min(aucs)), sprintf("(%.4f)", min(aucs)), "\n\n")
      }
    }
  }
}

# INTERSECTIONAL FINDINGS
if (exists("intersect_metrics_list") && length(intersect_metrics_list) >= 4) {
  cat("INTERSECTIONAL ANALYSIS\n")
  cat(strrep("-", 40), "\n")
  int_aucs <- sapply(intersect_metrics_list, function(x) x$auc)
  cat("Gender √ó Race intersections analyzed:", length(intersect_metrics_list), "\n")
  cat("AUC range:", sprintf("%.4f", max(int_aucs) - min(int_aucs)))
  if ((max(int_aucs) - min(int_aucs)) > 0.10) {
    cat(" ‚ö†Ô∏è  WARNING\n")
  } else {
    cat(" ‚úì OK\n")
  }
  cat("Best performing:", names(which.max(int_aucs)),
      sprintf("(AUC=%.4f)", max(int_aucs)), "\n")
  cat("Worst performing:", names(which.min(int_aucs)),
      sprintf("(AUC=%.4f)", min(int_aucs)), "\n")
  if ((max(int_aucs) - min(int_aucs)) > 0.10) {
    cat("\n‚ö†Ô∏è  WARNING: Compound disparities detected\n")
    cat("   Recommendation: Targeted model recalibration for underperforming groups\n")
  }
  cat("\n")
}

cat("\nRecommendations:\n")
cat(strrep("-", 40), "\n")
cat("1. Review subgroups with N <", MIN_SUBGROUP_SIZE, "for statistical reliability\n")
cat("2. Monitor groups with AUC < 0.80 for potential bias\n")
cat("3. Consider calibration adjustments for underperforming groups\n")
cat("4. Validate findings with external datasets\n")

sink()

cat("Report saved:", report_file, "\n\n")

# Final Summary ===============================================================
cat(strrep("=", 80) %+% "\n")
cat("DEMOGRAPHIC ANALYSIS COMPLETE\n")
cat(strrep("=", 80) %+% "\n\n")

cat("Summary:\n")
cat("  Test samples:", nrow(analysis_data), "\n")
cat("  Demographic variables:", paste(available_demos, collapse = ", "), "\n")
if (nrow(all_subgroup_metrics) > 0) {
  cat("  Subgroups analyzed:", nrow(all_subgroup_metrics) - 1, 
      "(excluding overall)\n")
}
cat("  Overall AUC:", sprintf("%.4f", overall_metrics$auc), "\n\n")

cat("Output Files:\n")
cat("  Results directory:", DEMO_RESULTS_DIR, "/\n")
cat("  Figures directory:", DEMO_FIGURES_DIR, "/\n\n")

cat("Generated Files:\n")
cat("  - subgroup_performance.csv\n")
cat("  - subgroup_performance.xlsx\n")
cat("  - subgroup_performance.rds\n")
cat("  - demographic_analysis_report.txt\n")
if (file.exists(file.path(DEMO_FIGURES_DIR, "auc_by_subgroup.png"))) {
  cat("  - auc_by_subgroup.png\n")
  cat("  - sensitivity_specificity.png\n")
  cat("  - metrics_comparison.png\n")
}
cat("\n")

cat("Next Steps:\n")
cat("  1. Review demographic_analysis_report.txt for key findings\n")
cat("  2. Check visualizations in figures/demographic/\n")
cat("  3. Assess fairness metrics and identify any disparities\n")
cat("  4. Run 05_inference.R to apply model to new data\n\n")

cat(strrep("=", 80) %+% "\n")
cat("Analysis completed successfully!\n")
cat(strrep("=", 80) %+% "\n")